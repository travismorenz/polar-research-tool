<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Key Phrases</title>
    <style type="text/css">
        table {
            float: left;
        }
    </style>
</head>
<body>


<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Key Phrase: TF-IDF</th>
      <th>Score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>adversarial example</td>
      <td>0.020695</td>
    </tr>
    <tr>
      <th>1</th>
      <td>neural network</td>
      <td>0.016169</td>
    </tr>
    <tr>
      <th>2</th>
      <td>adversarial attack</td>
      <td>0.011839</td>
    </tr>
    <tr>
      <th>3</th>
      <td>adversarial perturbation</td>
      <td>0.009720</td>
    </tr>
    <tr>
      <th>4</th>
      <td>deep neural</td>
      <td>0.009342</td>
    </tr>
    <tr>
      <th>5</th>
      <td>deep neural network</td>
      <td>0.009234</td>
    </tr>
    <tr>
      <th>6</th>
      <td>state art</td>
      <td>0.009170</td>
    </tr>
    <tr>
      <th>7</th>
      <td>adversarial training</td>
      <td>0.008955</td>
    </tr>
    <tr>
      <th>8</th>
      <td>black box</td>
      <td>0.008096</td>
    </tr>
    <tr>
      <th>9</th>
      <td>deep learning</td>
      <td>0.007000</td>
    </tr>
    <tr>
      <th>10</th>
      <td>vulnerable adversarial</td>
      <td>0.005684</td>
    </tr>
    <tr>
      <th>11</th>
      <td>machine learn</td>
      <td>0.005511</td>
    </tr>
    <tr>
      <th>12</th>
      <td>machine learning</td>
      <td>0.005492</td>
    </tr>
    <tr>
      <th>13</th>
      <td>adversarial image</td>
      <td>0.005255</td>
    </tr>
    <tr>
      <th>14</th>
      <td>learning model</td>
      <td>0.005109</td>
    </tr>
    <tr>
      <th>15</th>
      <td>box attack</td>
      <td>0.005061</td>
    </tr>
    <tr>
      <th>16</th>
      <td>adversarial sample</td>
      <td>0.004963</td>
    </tr>
    <tr>
      <th>17</th>
      <td>generate adversarial</td>
      <td>0.004626</td>
    </tr>
    <tr>
      <th>18</th>
      <td>image classification</td>
      <td>0.004563</td>
    </tr>
    <tr>
      <th>19</th>
      <td>network dnn</td>
      <td>0.004469</td>
    </tr>
    <tr>
      <th>20</th>
      <td>neural network dnn</td>
      <td>0.004469</td>
    </tr>
    <tr>
      <th>21</th>
      <td>convolutional neural network</td>
      <td>0.004086</td>
    </tr>
    <tr>
      <th>22</th>
      <td>convolutional neural</td>
      <td>0.004086</td>
    </tr>
    <tr>
      <th>23</th>
      <td>real world</td>
      <td>0.004011</td>
    </tr>
    <tr>
      <th>24</th>
      <td>propose method</td>
      <td>0.003995</td>
    </tr>
    <tr>
      <th>25</th>
      <td>black box attack</td>
      <td>0.003932</td>
    </tr>
    <tr>
      <th>26</th>
      <td>paper propose</td>
      <td>0.003890</td>
    </tr>
    <tr>
      <th>27</th>
      <td>training datum</td>
      <td>0.003829</td>
    </tr>
    <tr>
      <th>28</th>
      <td>white box</td>
      <td>0.003692</td>
    </tr>
    <tr>
      <th>29</th>
      <td>vulnerable adversarial example</td>
      <td>0.003510</td>
    </tr>
    <tr>
      <th>30</th>
      <td>improve robustness</td>
      <td>0.003433</td>
    </tr>
    <tr>
      <th>31</th>
      <td>success rate</td>
      <td>0.003363</td>
    </tr>
    <tr>
      <th>32</th>
      <td>attack method</td>
      <td>0.003356</td>
    </tr>
    <tr>
      <th>33</th>
      <td>machine learning model</td>
      <td>0.003342</td>
    </tr>
    <tr>
      <th>34</th>
      <td>mnist cifar</td>
      <td>0.003321</td>
    </tr>
    <tr>
      <th>35</th>
      <td>deep network</td>
      <td>0.003238</td>
    </tr>
    <tr>
      <th>36</th>
      <td>training set</td>
      <td>0.003179</td>
    </tr>
    <tr>
      <th>37</th>
      <td>generate adversarial example</td>
      <td>0.003171</td>
    </tr>
    <tr>
      <th>38</th>
      <td>computer vision</td>
      <td>0.003110</td>
    </tr>
    <tr>
      <th>39</th>
      <td>detect adversarial</td>
      <td>0.003050</td>
    </tr>
    <tr>
      <th>40</th>
      <td>train model</td>
      <td>0.003021</td>
    </tr>
    <tr>
      <th>41</th>
      <td>perturbation input</td>
      <td>0.002916</td>
    </tr>
    <tr>
      <th>42</th>
      <td>experimental result</td>
      <td>0.002916</td>
    </tr>
    <tr>
      <th>43</th>
      <td>adversarial network</td>
      <td>0.002817</td>
    </tr>
    <tr>
      <th>44</th>
      <td>base attack</td>
      <td>0.002781</td>
    </tr>
    <tr>
      <th>45</th>
      <td>result show</td>
      <td>0.002771</td>
    </tr>
    <tr>
      <th>46</th>
      <td>input image</td>
      <td>0.002769</td>
    </tr>
    <tr>
      <th>47</th>
      <td>adversarial robustness</td>
      <td>0.002742</td>
    </tr>
    <tr>
      <th>48</th>
      <td>learn algorithm</td>
      <td>0.002715</td>
    </tr>
    <tr>
      <th>49</th>
      <td>generative adversarial</td>
      <td>0.002665</td>
    </tr>
    <tr>
      <th>50</th>
      <td>deep learn</td>
      <td>0.002639</td>
    </tr>
    <tr>
      <th>51</th>
      <td>generative model</td>
      <td>0.002596</td>
    </tr>
    <tr>
      <th>52</th>
      <td>small perturbation</td>
      <td>0.002586</td>
    </tr>
    <tr>
      <th>53</th>
      <td>target model</td>
      <td>0.002576</td>
    </tr>
    <tr>
      <th>54</th>
      <td>robustness adversarial</td>
      <td>0.002563</td>
    </tr>
    <tr>
      <th>55</th>
      <td>recent work</td>
      <td>0.002538</td>
    </tr>
    <tr>
      <th>56</th>
      <td>deep learning model</td>
      <td>0.002503</td>
    </tr>
    <tr>
      <th>57</th>
      <td>network adversarial</td>
      <td>0.002500</td>
    </tr>
    <tr>
      <th>58</th>
      <td>classification task</td>
      <td>0.002486</td>
    </tr>
    <tr>
      <th>59</th>
      <td>natural image</td>
      <td>0.002480</td>
    </tr>
    <tr>
      <th>60</th>
      <td>experiment show</td>
      <td>0.002460</td>
    </tr>
    <tr>
      <th>61</th>
      <td>decision boundary</td>
      <td>0.002439</td>
    </tr>
    <tr>
      <th>62</th>
      <td>generative adversarial network</td>
      <td>0.002437</td>
    </tr>
    <tr>
      <th>63</th>
      <td>threat model</td>
      <td>0.002423</td>
    </tr>
    <tr>
      <th>64</th>
      <td>network train</td>
      <td>0.002390</td>
    </tr>
    <tr>
      <th>65</th>
      <td>defense method</td>
      <td>0.002361</td>
    </tr>
    <tr>
      <th>66</th>
      <td>face recognition</td>
      <td>0.002329</td>
    </tr>
    <tr>
      <th>67</th>
      <td>robust adversarial</td>
      <td>0.002326</td>
    </tr>
    <tr>
      <th>68</th>
      <td>object detection</td>
      <td>0.002320</td>
    </tr>
    <tr>
      <th>69</th>
      <td>extensive experiment</td>
      <td>0.002208</td>
    </tr>
    <tr>
      <th>70</th>
      <td>universal perturbation</td>
      <td>0.002161</td>
    </tr>
    <tr>
      <th>71</th>
      <td>object detector</td>
      <td>0.002147</td>
    </tr>
    <tr>
      <th>72</th>
      <td>imperceptible perturbation</td>
      <td>0.002131</td>
    </tr>
    <tr>
      <th>73</th>
      <td>example generate</td>
      <td>0.002126</td>
    </tr>
    <tr>
      <th>74</th>
      <td>image classifier</td>
      <td>0.002119</td>
    </tr>
    <tr>
      <th>75</th>
      <td>vulnerable adversarial attack</td>
      <td>0.002111</td>
    </tr>
    <tr>
      <th>76</th>
      <td>network architecture</td>
      <td>0.002090</td>
    </tr>
    <tr>
      <th>77</th>
      <td>learning system</td>
      <td>0.002083</td>
    </tr>
    <tr>
      <th>78</th>
      <td>adversarial example generate</td>
      <td>0.002075</td>
    </tr>
    <tr>
      <th>79</th>
      <td>network vulnerable</td>
      <td>0.002071</td>
    </tr>
    <tr>
      <th>80</th>
      <td>adversarial input</td>
      <td>0.002070</td>
    </tr>
    <tr>
      <th>81</th>
      <td>detect adversarial example</td>
      <td>0.002055</td>
    </tr>
    <tr>
      <th>82</th>
      <td>work show</td>
      <td>0.002038</td>
    </tr>
    <tr>
      <th>83</th>
      <td>show vulnerable</td>
      <td>0.002022</td>
    </tr>
    <tr>
      <th>84</th>
      <td>method generate</td>
      <td>0.002016</td>
    </tr>
    <tr>
      <th>85</th>
      <td>state art performance</td>
      <td>0.002002</td>
    </tr>
    <tr>
      <th>86</th>
      <td>art performance</td>
      <td>0.002002</td>
    </tr>
    <tr>
      <th>87</th>
      <td>recent study</td>
      <td>0.001992</td>
    </tr>
    <tr>
      <th>88</th>
      <td>loss function</td>
      <td>0.001958</td>
    </tr>
    <tr>
      <th>89</th>
      <td>propose defense</td>
      <td>0.001942</td>
    </tr>
    <tr>
      <th>90</th>
      <td>bad case</td>
      <td>0.001934</td>
    </tr>
    <tr>
      <th>91</th>
      <td>high dimensional</td>
      <td>0.001926</td>
    </tr>
    <tr>
      <th>92</th>
      <td>neural network vulnerable</td>
      <td>0.001906</td>
    </tr>
    <tr>
      <th>93</th>
      <td>achieve state art</td>
      <td>0.001900</td>
    </tr>
    <tr>
      <th>94</th>
      <td>achieve state</td>
      <td>0.001900</td>
    </tr>
    <tr>
      <th>95</th>
      <td>network vulnerable adversarial</td>
      <td>0.001870</td>
    </tr>
    <tr>
      <th>96</th>
      <td>adversarial defense</td>
      <td>0.001842</td>
    </tr>
    <tr>
      <th>97</th>
      <td>safety critical</td>
      <td>0.001832</td>
    </tr>
    <tr>
      <th>98</th>
      <td>art attack</td>
      <td>0.001829</td>
    </tr>
    <tr>
      <th>99</th>
      <td>learn model</td>
      <td>0.001824</td>
    </tr>
    <tr>
      <th>100</th>
      <td>defense mechanism</td>
      <td>0.001822</td>
    </tr>
    <tr>
      <th>101</th>
      <td>imperceptible human</td>
      <td>0.001800</td>
    </tr>
    <tr>
      <th>102</th>
      <td>wide range</td>
      <td>0.001795</td>
    </tr>
    <tr>
      <th>103</th>
      <td>recognition system</td>
      <td>0.001795</td>
    </tr>
    <tr>
      <th>104</th>
      <td>attack algorithm</td>
      <td>0.001793</td>
    </tr>
    <tr>
      <th>105</th>
      <td>network cnn</td>
      <td>0.001791</td>
    </tr>
    <tr>
      <th>106</th>
      <td>neural network adversarial</td>
      <td>0.001781</td>
    </tr>
    <tr>
      <th>107</th>
      <td>state art attack</td>
      <td>0.001779</td>
    </tr>
    <tr>
      <th>108</th>
      <td>attack adversarial</td>
      <td>0.001771</td>
    </tr>
    <tr>
      <th>109</th>
      <td>craft adversarial</td>
      <td>0.001770</td>
    </tr>
    <tr>
      <th>110</th>
      <td>model train</td>
      <td>0.001751</td>
    </tr>
    <tr>
      <th>111</th>
      <td>show adversarial</td>
      <td>0.001745</td>
    </tr>
    <tr>
      <th>112</th>
      <td>point cloud</td>
      <td>0.001745</td>
    </tr>
    <tr>
      <th>113</th>
      <td>adversarial noise</td>
      <td>0.001738</td>
    </tr>
    <tr>
      <th>114</th>
      <td>defense adversarial</td>
      <td>0.001737</td>
    </tr>
    <tr>
      <th>115</th>
      <td>neural network cnn</td>
      <td>0.001735</td>
    </tr>
    <tr>
      <th>116</th>
      <td>propose algorithm</td>
      <td>0.001728</td>
    </tr>
    <tr>
      <th>117</th>
      <td>train deep</td>
      <td>0.001713</td>
    </tr>
    <tr>
      <th>118</th>
      <td>test time</td>
      <td>0.001711</td>
    </tr>
    <tr>
      <th>119</th>
      <td>image space</td>
      <td>0.001709</td>
    </tr>
    <tr>
      <th>120</th>
      <td>work propose</td>
      <td>0.001707</td>
    </tr>
    <tr>
      <th>121</th>
      <td>carefully craft</td>
      <td>0.001684</td>
    </tr>
    <tr>
      <th>122</th>
      <td>deep convolutional</td>
      <td>0.001683</td>
    </tr>
    <tr>
      <th>123</th>
      <td>white box attack</td>
      <td>0.001673</td>
    </tr>
    <tr>
      <th>124</th>
      <td>vulnerable adversarial perturbation</td>
      <td>0.001641</td>
    </tr>
    <tr>
      <th>125</th>
      <td>pre train</td>
      <td>0.001631</td>
    </tr>
    <tr>
      <th>126</th>
      <td>robustness deep</td>
      <td>0.001624</td>
    </tr>
    <tr>
      <th>127</th>
      <td>network show</td>
      <td>0.001615</td>
    </tr>
    <tr>
      <th>128</th>
      <td>model adversarial</td>
      <td>0.001594</td>
    </tr>
    <tr>
      <th>129</th>
      <td>study show</td>
      <td>0.001594</td>
    </tr>
    <tr>
      <th>130</th>
      <td>cifar imagenet</td>
      <td>0.001593</td>
    </tr>
    <tr>
      <th>131</th>
      <td>box adversarial</td>
      <td>0.001590</td>
    </tr>
    <tr>
      <th>132</th>
      <td>defensive distillation</td>
      <td>0.001588</td>
    </tr>
    <tr>
      <th>133</th>
      <td>machine learn algorithm</td>
      <td>0.001585</td>
    </tr>
    <tr>
      <th>134</th>
      <td>original image</td>
      <td>0.001584</td>
    </tr>
    <tr>
      <th>135</th>
      <td>show propose</td>
      <td>0.001583</td>
    </tr>
    <tr>
      <th>136</th>
      <td>large scale</td>
      <td>0.001581</td>
    </tr>
    <tr>
      <th>137</th>
      <td>universal adversarial</td>
      <td>0.001572</td>
    </tr>
    <tr>
      <th>138</th>
      <td>poisoning attack</td>
      <td>0.001571</td>
    </tr>
    <tr>
      <th>139</th>
      <td>increase robustness</td>
      <td>0.001558</td>
    </tr>
    <tr>
      <th>140</th>
      <td>input datum</td>
      <td>0.001545</td>
    </tr>
    <tr>
      <th>141</th>
      <td>find adversarial</td>
      <td>0.001541</td>
    </tr>
    <tr>
      <th>142</th>
      <td>recent year</td>
      <td>0.001533</td>
    </tr>
    <tr>
      <th>143</th>
      <td>network model</td>
      <td>0.001533</td>
    </tr>
    <tr>
      <th>144</th>
      <td>defend adversarial</td>
      <td>0.001516</td>
    </tr>
    <tr>
      <th>145</th>
      <td>defense strategy</td>
      <td>0.001515</td>
    </tr>
    <tr>
      <th>146</th>
      <td>previous work</td>
      <td>0.001509</td>
    </tr>
    <tr>
      <th>147</th>
      <td>semantic segmentation</td>
      <td>0.001498</td>
    </tr>
    <tr>
      <th>148</th>
      <td>dataset show</td>
      <td>0.001494</td>
    </tr>
    <tr>
      <th>149</th>
      <td>base adversarial</td>
      <td>0.001492</td>
    </tr>
  </tbody>
</table><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Key Phrase: LDA</th>
      <th>Score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>adversarial example</td>
      <td>0.029274</td>
    </tr>
    <tr>
      <th>1</th>
      <td>neural network</td>
      <td>0.028611</td>
    </tr>
    <tr>
      <th>2</th>
      <td>adversarial attack</td>
      <td>0.015720</td>
    </tr>
    <tr>
      <th>3</th>
      <td>state art</td>
      <td>0.012850</td>
    </tr>
    <tr>
      <th>4</th>
      <td>adversarial training</td>
      <td>0.011924</td>
    </tr>
    <tr>
      <th>5</th>
      <td>deep neural</td>
      <td>0.011518</td>
    </tr>
    <tr>
      <th>6</th>
      <td>deep neural network</td>
      <td>0.011345</td>
    </tr>
    <tr>
      <th>7</th>
      <td>adversarial perturbation</td>
      <td>0.010350</td>
    </tr>
    <tr>
      <th>8</th>
      <td>black box</td>
      <td>0.007992</td>
    </tr>
    <tr>
      <th>9</th>
      <td>deep learning</td>
      <td>0.005933</td>
    </tr>
    <tr>
      <th>10</th>
      <td>vulnerable adversarial</td>
      <td>0.005283</td>
    </tr>
    <tr>
      <th>11</th>
      <td>adversarial image</td>
      <td>0.004791</td>
    </tr>
    <tr>
      <th>12</th>
      <td>network dnn</td>
      <td>0.004085</td>
    </tr>
    <tr>
      <th>13</th>
      <td>neural network dnn</td>
      <td>0.004085</td>
    </tr>
    <tr>
      <th>14</th>
      <td>machine learning</td>
      <td>0.004001</td>
    </tr>
    <tr>
      <th>15</th>
      <td>box attack</td>
      <td>0.003963</td>
    </tr>
    <tr>
      <th>16</th>
      <td>generate adversarial</td>
      <td>0.003920</td>
    </tr>
    <tr>
      <th>17</th>
      <td>paper propose</td>
      <td>0.003645</td>
    </tr>
    <tr>
      <th>18</th>
      <td>adversarial sample</td>
      <td>0.003638</td>
    </tr>
    <tr>
      <th>19</th>
      <td>machine learn</td>
      <td>0.003612</td>
    </tr>
    <tr>
      <th>20</th>
      <td>mnist cifar</td>
      <td>0.003587</td>
    </tr>
    <tr>
      <th>21</th>
      <td>attack method</td>
      <td>0.003490</td>
    </tr>
    <tr>
      <th>22</th>
      <td>improve robustness</td>
      <td>0.003421</td>
    </tr>
    <tr>
      <th>23</th>
      <td>convolutional neural</td>
      <td>0.003380</td>
    </tr>
    <tr>
      <th>24</th>
      <td>convolutional neural network</td>
      <td>0.003380</td>
    </tr>
    <tr>
      <th>25</th>
      <td>propose method</td>
      <td>0.003355</td>
    </tr>
    <tr>
      <th>26</th>
      <td>image classification</td>
      <td>0.003159</td>
    </tr>
    <tr>
      <th>27</th>
      <td>learning model</td>
      <td>0.003145</td>
    </tr>
    <tr>
      <th>28</th>
      <td>training datum</td>
      <td>0.003083</td>
    </tr>
    <tr>
      <th>29</th>
      <td>white box</td>
      <td>0.003022</td>
    </tr>
    <tr>
      <th>30</th>
      <td>black box attack</td>
      <td>0.002725</td>
    </tr>
    <tr>
      <th>31</th>
      <td>real world</td>
      <td>0.002688</td>
    </tr>
    <tr>
      <th>32</th>
      <td>network adversarial</td>
      <td>0.002580</td>
    </tr>
    <tr>
      <th>33</th>
      <td>small perturbation</td>
      <td>0.002394</td>
    </tr>
    <tr>
      <th>34</th>
      <td>train model</td>
      <td>0.002393</td>
    </tr>
    <tr>
      <th>35</th>
      <td>adversarial network</td>
      <td>0.002388</td>
    </tr>
    <tr>
      <th>36</th>
      <td>vulnerable adversarial example</td>
      <td>0.002378</td>
    </tr>
    <tr>
      <th>37</th>
      <td>base attack</td>
      <td>0.002340</td>
    </tr>
    <tr>
      <th>38</th>
      <td>generative adversarial</td>
      <td>0.002282</td>
    </tr>
    <tr>
      <th>39</th>
      <td>success rate</td>
      <td>0.002245</td>
    </tr>
    <tr>
      <th>40</th>
      <td>art attack</td>
      <td>0.002238</td>
    </tr>
    <tr>
      <th>41</th>
      <td>experimental result</td>
      <td>0.002203</td>
    </tr>
    <tr>
      <th>42</th>
      <td>perturbation input</td>
      <td>0.002150</td>
    </tr>
    <tr>
      <th>43</th>
      <td>generative adversarial network</td>
      <td>0.002071</td>
    </tr>
    <tr>
      <th>44</th>
      <td>adversarial input</td>
      <td>0.002070</td>
    </tr>
    <tr>
      <th>45</th>
      <td>computer vision</td>
      <td>0.002068</td>
    </tr>
    <tr>
      <th>46</th>
      <td>state art attack</td>
      <td>0.002067</td>
    </tr>
    <tr>
      <th>47</th>
      <td>deep network</td>
      <td>0.001979</td>
    </tr>
    <tr>
      <th>48</th>
      <td>recent work</td>
      <td>0.001919</td>
    </tr>
    <tr>
      <th>49</th>
      <td>result show</td>
      <td>0.001903</td>
    </tr>
    <tr>
      <th>50</th>
      <td>experiment show</td>
      <td>0.001898</td>
    </tr>
    <tr>
      <th>51</th>
      <td>adversarial robustness</td>
      <td>0.001852</td>
    </tr>
    <tr>
      <th>52</th>
      <td>example generate</td>
      <td>0.001851</td>
    </tr>
    <tr>
      <th>53</th>
      <td>propose defense</td>
      <td>0.001828</td>
    </tr>
    <tr>
      <th>54</th>
      <td>generate adversarial example</td>
      <td>0.001817</td>
    </tr>
    <tr>
      <th>55</th>
      <td>adversarial example generate</td>
      <td>0.001811</td>
    </tr>
    <tr>
      <th>56</th>
      <td>robustness adversarial</td>
      <td>0.001725</td>
    </tr>
    <tr>
      <th>57</th>
      <td>deep learn</td>
      <td>0.001688</td>
    </tr>
    <tr>
      <th>58</th>
      <td>machine learning model</td>
      <td>0.001686</td>
    </tr>
    <tr>
      <th>59</th>
      <td>network train</td>
      <td>0.001686</td>
    </tr>
    <tr>
      <th>60</th>
      <td>increase robustness</td>
      <td>0.001678</td>
    </tr>
    <tr>
      <th>61</th>
      <td>input image</td>
      <td>0.001677</td>
    </tr>
    <tr>
      <th>62</th>
      <td>neural network adversarial</td>
      <td>0.001676</td>
    </tr>
    <tr>
      <th>63</th>
      <td>object detection</td>
      <td>0.001668</td>
    </tr>
    <tr>
      <th>64</th>
      <td>extensive experiment</td>
      <td>0.001664</td>
    </tr>
    <tr>
      <th>65</th>
      <td>network architecture</td>
      <td>0.001657</td>
    </tr>
    <tr>
      <th>66</th>
      <td>train neural</td>
      <td>0.001652</td>
    </tr>
    <tr>
      <th>67</th>
      <td>imperceptible perturbation</td>
      <td>0.001618</td>
    </tr>
    <tr>
      <th>68</th>
      <td>defense strategy</td>
      <td>0.001617</td>
    </tr>
    <tr>
      <th>69</th>
      <td>training set</td>
      <td>0.001580</td>
    </tr>
    <tr>
      <th>70</th>
      <td>pre train</td>
      <td>0.001574</td>
    </tr>
    <tr>
      <th>71</th>
      <td>detect adversarial</td>
      <td>0.001551</td>
    </tr>
    <tr>
      <th>72</th>
      <td>input space</td>
      <td>0.001543</td>
    </tr>
    <tr>
      <th>73</th>
      <td>train neural network</td>
      <td>0.001536</td>
    </tr>
    <tr>
      <th>74</th>
      <td>target model</td>
      <td>0.001535</td>
    </tr>
    <tr>
      <th>75</th>
      <td>art performance</td>
      <td>0.001529</td>
    </tr>
    <tr>
      <th>76</th>
      <td>state art performance</td>
      <td>0.001529</td>
    </tr>
    <tr>
      <th>77</th>
      <td>vulnerable adversarial attack</td>
      <td>0.001519</td>
    </tr>
    <tr>
      <th>78</th>
      <td>box adversarial</td>
      <td>0.001509</td>
    </tr>
    <tr>
      <th>79</th>
      <td>generative model</td>
      <td>0.001490</td>
    </tr>
    <tr>
      <th>80</th>
      <td>benchmark dataset</td>
      <td>0.001465</td>
    </tr>
    <tr>
      <th>81</th>
      <td>image classifier</td>
      <td>0.001459</td>
    </tr>
    <tr>
      <th>82</th>
      <td>network show</td>
      <td>0.001446</td>
    </tr>
    <tr>
      <th>83</th>
      <td>network cnn</td>
      <td>0.001427</td>
    </tr>
    <tr>
      <th>84</th>
      <td>learn algorithm</td>
      <td>0.001419</td>
    </tr>
    <tr>
      <th>85</th>
      <td>high dimensional</td>
      <td>0.001404</td>
    </tr>
    <tr>
      <th>86</th>
      <td>deep convolutional</td>
      <td>0.001388</td>
    </tr>
    <tr>
      <th>87</th>
      <td>show vulnerable</td>
      <td>0.001379</td>
    </tr>
    <tr>
      <th>88</th>
      <td>neural network cnn</td>
      <td>0.001376</td>
    </tr>
    <tr>
      <th>89</th>
      <td>threat model</td>
      <td>0.001368</td>
    </tr>
    <tr>
      <th>90</th>
      <td>deep learning model</td>
      <td>0.001365</td>
    </tr>
    <tr>
      <th>91</th>
      <td>natural image</td>
      <td>0.001347</td>
    </tr>
    <tr>
      <th>92</th>
      <td>carefully craft</td>
      <td>0.001339</td>
    </tr>
    <tr>
      <th>93</th>
      <td>ser system</td>
      <td>0.001326</td>
    </tr>
    <tr>
      <th>94</th>
      <td>defense method</td>
      <td>0.001310</td>
    </tr>
    <tr>
      <th>95</th>
      <td>robust adversarial</td>
      <td>0.001303</td>
    </tr>
    <tr>
      <th>96</th>
      <td>bad case</td>
      <td>0.001301</td>
    </tr>
    <tr>
      <th>97</th>
      <td>achieve state art</td>
      <td>0.001295</td>
    </tr>
    <tr>
      <th>98</th>
      <td>achieve state</td>
      <td>0.001295</td>
    </tr>
    <tr>
      <th>99</th>
      <td>network adversarial example</td>
      <td>0.001287</td>
    </tr>
    <tr>
      <th>100</th>
      <td>adversarially train</td>
      <td>0.001283</td>
    </tr>
    <tr>
      <th>101</th>
      <td>defense mechanism</td>
      <td>0.001280</td>
    </tr>
    <tr>
      <th>102</th>
      <td>box adversarial attack</td>
      <td>0.001274</td>
    </tr>
    <tr>
      <th>103</th>
      <td>defense model</td>
      <td>0.001264</td>
    </tr>
    <tr>
      <th>104</th>
      <td>show vulnerable adversarial</td>
      <td>0.001263</td>
    </tr>
    <tr>
      <th>105</th>
      <td>original image</td>
      <td>0.001239</td>
    </tr>
    <tr>
      <th>106</th>
      <td>adversarial defense</td>
      <td>0.001235</td>
    </tr>
    <tr>
      <th>107</th>
      <td>imperceptible human</td>
      <td>0.001229</td>
    </tr>
    <tr>
      <th>108</th>
      <td>classification task</td>
      <td>0.001224</td>
    </tr>
    <tr>
      <th>109</th>
      <td>craft adversarial</td>
      <td>0.001220</td>
    </tr>
    <tr>
      <th>110</th>
      <td>white box attack</td>
      <td>0.001220</td>
    </tr>
    <tr>
      <th>111</th>
      <td>face recognition</td>
      <td>0.001212</td>
    </tr>
    <tr>
      <th>112</th>
      <td>gradient sign</td>
      <td>0.001202</td>
    </tr>
    <tr>
      <th>113</th>
      <td>step adversarial</td>
      <td>0.001200</td>
    </tr>
    <tr>
      <th>114</th>
      <td>fast gradient</td>
      <td>0.001195</td>
    </tr>
    <tr>
      <th>115</th>
      <td>model robustness</td>
      <td>0.001190</td>
    </tr>
    <tr>
      <th>116</th>
      <td>vulnerable adversarial perturbation</td>
      <td>0.001189</td>
    </tr>
    <tr>
      <th>117</th>
      <td>fast gradient sign</td>
      <td>0.001185</td>
    </tr>
    <tr>
      <th>118</th>
      <td>recent study</td>
      <td>0.001184</td>
    </tr>
    <tr>
      <th>119</th>
      <td>model adversarial</td>
      <td>0.001182</td>
    </tr>
    <tr>
      <th>120</th>
      <td>outperform state art</td>
      <td>0.001173</td>
    </tr>
    <tr>
      <th>121</th>
      <td>outperform state</td>
      <td>0.001173</td>
    </tr>
    <tr>
      <th>122</th>
      <td>significantly improve</td>
      <td>0.001170</td>
    </tr>
    <tr>
      <th>123</th>
      <td>simple effective</td>
      <td>0.001157</td>
    </tr>
    <tr>
      <th>124</th>
      <td>confidence attack</td>
      <td>0.001154</td>
    </tr>
    <tr>
      <th>125</th>
      <td>attack adversarial</td>
      <td>0.001152</td>
    </tr>
    <tr>
      <th>126</th>
      <td>loss function</td>
      <td>0.001151</td>
    </tr>
    <tr>
      <th>127</th>
      <td>attack algorithm</td>
      <td>0.001150</td>
    </tr>
    <tr>
      <th>128</th>
      <td>cifar imagenet</td>
      <td>0.001146</td>
    </tr>
    <tr>
      <th>129</th>
      <td>gradient descent</td>
      <td>0.001146</td>
    </tr>
    <tr>
      <th>130</th>
      <td>neural network show</td>
      <td>0.001128</td>
    </tr>
    <tr>
      <th>131</th>
      <td>find adversarial</td>
      <td>0.001127</td>
    </tr>
    <tr>
      <th>132</th>
      <td>attack scenario</td>
      <td>0.001125</td>
    </tr>
    <tr>
      <th>133</th>
      <td>robustness deep</td>
      <td>0.001117</td>
    </tr>
    <tr>
      <th>134</th>
      <td>recent year</td>
      <td>0.001107</td>
    </tr>
    <tr>
      <th>135</th>
      <td>safety critical</td>
      <td>0.001103</td>
    </tr>
    <tr>
      <th>136</th>
      <td>paper present</td>
      <td>0.001096</td>
    </tr>
    <tr>
      <th>137</th>
      <td>universal perturbation</td>
      <td>0.001093</td>
    </tr>
    <tr>
      <th>138</th>
      <td>propose approach</td>
      <td>0.001092</td>
    </tr>
    <tr>
      <th>139</th>
      <td>training method</td>
      <td>0.001087</td>
    </tr>
    <tr>
      <th>140</th>
      <td>large scale</td>
      <td>0.001081</td>
    </tr>
    <tr>
      <th>141</th>
      <td>art model</td>
      <td>0.001079</td>
    </tr>
    <tr>
      <th>142</th>
      <td>multi step</td>
      <td>0.001066</td>
    </tr>
    <tr>
      <th>143</th>
      <td>attack paper</td>
      <td>0.001064</td>
    </tr>
    <tr>
      <th>144</th>
      <td>network vulnerable</td>
      <td>0.001064</td>
    </tr>
    <tr>
      <th>145</th>
      <td>propose algorithm</td>
      <td>0.001063</td>
    </tr>
    <tr>
      <th>146</th>
      <td>detect adversarial example</td>
      <td>0.001063</td>
    </tr>
    <tr>
      <th>147</th>
      <td>robustness neural</td>
      <td>0.001054</td>
    </tr>
    <tr>
      <th>148</th>
      <td>decision boundary</td>
      <td>0.001052</td>
    </tr>
    <tr>
      <th>149</th>
      <td>learning system</td>
      <td>0.001051</td>
    </tr>
  </tbody>
</table><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Key Phrase: Text Rank</th>
      <th>Score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>vulnerable adversarial example</td>
      <td>0.147765</td>
    </tr>
    <tr>
      <th>1</th>
      <td>attacker restrict</td>
      <td>0.127711</td>
    </tr>
    <tr>
      <th>2</th>
      <td>existence robust</td>
      <td>0.095672</td>
    </tr>
    <tr>
      <th>3</th>
      <td>adversary access underlying</td>
      <td>0.092814</td>
    </tr>
    <tr>
      <th>4</th>
      <td>train subset dataset</td>
      <td>0.090718</td>
    </tr>
    <tr>
      <th>5</th>
      <td>machine learning</td>
      <td>0.087259</td>
    </tr>
    <tr>
      <th>6</th>
      <td>variety medical imaging</td>
      <td>0.083123</td>
    </tr>
    <tr>
      <th>7</th>
      <td>robustness reduce</td>
      <td>0.080361</td>
    </tr>
    <tr>
      <th>8</th>
      <td>conditional generative</td>
      <td>0.067095</td>
    </tr>
    <tr>
      <th>9</th>
      <td>input output mapping</td>
      <td>0.063550</td>
    </tr>
    <tr>
      <th>10</th>
      <td>typically construct perturb existing</td>
      <td>0.062848</td>
    </tr>
    <tr>
      <th>11</th>
      <td>classify incorrectly</td>
      <td>0.061438</td>
    </tr>
    <tr>
      <th>12</th>
      <td>important problem</td>
      <td>0.061117</td>
    </tr>
    <tr>
      <th>13</th>
      <td>base pattern</td>
      <td>0.060207</td>
    </tr>
    <tr>
      <th>14</th>
      <td>recent study</td>
      <td>0.060165</td>
    </tr>
    <tr>
      <th>15</th>
      <td>recognition task paper</td>
      <td>0.059603</td>
    </tr>
    <tr>
      <th>16</th>
      <td>concern perform</td>
      <td>0.055877</td>
    </tr>
    <tr>
      <th>17</th>
      <td>measure classification accuracy</td>
      <td>0.054803</td>
    </tr>
    <tr>
      <th>18</th>
      <td>datum modify slightly</td>
      <td>0.051233</td>
    </tr>
    <tr>
      <th>19</th>
      <td>propose synthesize realistic</td>
      <td>0.050986</td>
    </tr>
    <tr>
      <th>20</th>
      <td>object exist real world</td>
      <td>0.049673</td>
    </tr>
    <tr>
      <th>21</th>
      <td>defensive distillation</td>
      <td>0.048211</td>
    </tr>
    <tr>
      <th>22</th>
      <td>computationally efficient</td>
      <td>0.047401</td>
    </tr>
    <tr>
      <th>23</th>
      <td>prediction error</td>
      <td>0.046980</td>
    </tr>
    <tr>
      <th>24</th>
      <td>security non</td>
      <td>0.044806</td>
    </tr>
    <tr>
      <th>25</th>
      <td>semantic information</td>
      <td>0.044471</td>
    </tr>
    <tr>
      <th>26</th>
      <td>specific nature</td>
      <td>0.042768</td>
    </tr>
    <tr>
      <th>27</th>
      <td>defense attempt create</td>
      <td>0.042625</td>
    </tr>
    <tr>
      <th>28</th>
      <td>parameter gradient</td>
      <td>0.041825</td>
    </tr>
    <tr>
      <th>29</th>
      <td>free set additive term</td>
      <td>0.040437</td>
    </tr>
    <tr>
      <th>30</th>
      <td>pron goal</td>
      <td>0.039135</td>
    </tr>
    <tr>
      <th>31</th>
      <td>knowledge transfer</td>
      <td>0.039117</td>
    </tr>
    <tr>
      <th>32</th>
      <td>effective bad furthermore</td>
      <td>0.038780</td>
    </tr>
    <tr>
      <th>33</th>
      <td>evaluate safety</td>
      <td>0.038697</td>
    </tr>
    <tr>
      <th>34</th>
      <td>researcher develop</td>
      <td>0.038531</td>
    </tr>
    <tr>
      <th>35</th>
      <td>extensive experiment</td>
      <td>0.036988</td>
    </tr>
    <tr>
      <th>36</th>
      <td>generally offer</td>
      <td>0.036943</td>
    </tr>
    <tr>
      <th>37</th>
      <td>computational implementation</td>
      <td>0.035700</td>
    </tr>
    <tr>
      <th>38</th>
      <td>informative baseline</td>
      <td>0.035568</td>
    </tr>
    <tr>
      <th>39</th>
      <td>large fraction</td>
      <td>0.035321</td>
    </tr>
    <tr>
      <th>40</th>
      <td>choose distribution</td>
      <td>0.035041</td>
    </tr>
    <tr>
      <th>41</th>
      <td>degree improve</td>
      <td>0.034711</td>
    </tr>
    <tr>
      <th>42</th>
      <td>consistently fool</td>
      <td>0.034536</td>
    </tr>
    <tr>
      <th>43</th>
      <td>suggest space</td>
      <td>0.033902</td>
    </tr>
    <tr>
      <th>44</th>
      <td>require collect</td>
      <td>0.033443</td>
    </tr>
    <tr>
      <th>45</th>
      <td>imperceptibly original</td>
      <td>0.032621</td>
    </tr>
    <tr>
      <th>46</th>
      <td>limitation current</td>
      <td>0.032176</td>
    </tr>
    <tr>
      <th>47</th>
      <td>arbitrary malicious target hide</td>
      <td>0.031794</td>
    </tr>
    <tr>
      <th>48</th>
      <td>len distributionally</td>
      <td>0.031337</td>
    </tr>
    <tr>
      <th>49</th>
      <td>successful distil</td>
      <td>0.031117</td>
    </tr>
    <tr>
      <th>50</th>
      <td>depth analysis transferability</td>
      <td>0.030897</td>
    </tr>
    <tr>
      <th>51</th>
      <td>labeling criterion</td>
      <td>0.030526</td>
    </tr>
    <tr>
      <th>52</th>
      <td>minimal loss</td>
      <td>0.030351</td>
    </tr>
    <tr>
      <th>53</th>
      <td>point small matrix norm</td>
      <td>0.029644</td>
    </tr>
    <tr>
      <th>54</th>
      <td>processing compression</td>
      <td>0.028953</td>
    </tr>
    <tr>
      <th>55</th>
      <td>variational functional</td>
      <td>0.028694</td>
    </tr>
    <tr>
      <th>56</th>
      <td>manipulation exploration</td>
      <td>0.028249</td>
    </tr>
    <tr>
      <th>57</th>
      <td>systematic general purpose</td>
      <td>0.027957</td>
    </tr>
    <tr>
      <th>58</th>
      <td>significance discover</td>
      <td>0.027341</td>
    </tr>
    <tr>
      <th>59</th>
      <td>discrimination final</td>
      <td>0.027324</td>
    </tr>
    <tr>
      <th>60</th>
      <td>observe maximal</td>
      <td>0.027308</td>
    </tr>
    <tr>
      <th>61</th>
      <td>node additional</td>
      <td>0.027069</td>
    </tr>
    <tr>
      <th>62</th>
      <td>strategy selection</td>
      <td>0.026992</td>
    </tr>
    <tr>
      <th>63</th>
      <td>direction topic</td>
      <td>0.026967</td>
    </tr>
    <tr>
      <th>64</th>
      <td>black box</td>
      <td>0.026111</td>
    </tr>
    <tr>
      <th>65</th>
      <td>diverse potentially</td>
      <td>0.026049</td>
    </tr>
    <tr>
      <th>66</th>
      <td>naturally occur</td>
      <td>0.025934</td>
    </tr>
    <tr>
      <th>67</th>
      <td>significant extend</td>
      <td>0.025640</td>
    </tr>
    <tr>
      <th>68</th>
      <td>operate physical</td>
      <td>0.025521</td>
    </tr>
    <tr>
      <th>69</th>
      <td>computing embed accelerator</td>
      <td>0.024831</td>
    </tr>
    <tr>
      <th>70</th>
      <td>business increasingly</td>
      <td>0.024567</td>
    </tr>
    <tr>
      <th>71</th>
      <td>exploit randomization obfuscate</td>
      <td>0.024397</td>
    </tr>
    <tr>
      <th>72</th>
      <td>assign incorrect label</td>
      <td>0.024309</td>
    </tr>
    <tr>
      <th>73</th>
      <td>future challenge</td>
      <td>0.024142</td>
    </tr>
    <tr>
      <th>74</th>
      <td>case modification</td>
      <td>0.023999</td>
    </tr>
    <tr>
      <th>75</th>
      <td>statistical estimation</td>
      <td>0.023714</td>
    </tr>
    <tr>
      <th>76</th>
      <td>observer notice</td>
      <td>0.023508</td>
    </tr>
    <tr>
      <th>77</th>
      <td>sensitivity depend</td>
      <td>0.023191</td>
    </tr>
    <tr>
      <th>78</th>
      <td>allow pixel</td>
      <td>0.023133</td>
    </tr>
    <tr>
      <th>79</th>
      <td>physically implementable</td>
      <td>0.023128</td>
    </tr>
    <tr>
      <th>80</th>
      <td>add slight</td>
      <td>0.023021</td>
    </tr>
    <tr>
      <th>81</th>
      <td>low flexibility</td>
      <td>0.022695</td>
    </tr>
    <tr>
      <th>82</th>
      <td>countermeasure investigate research field</td>
      <td>0.022685</td>
    </tr>
    <tr>
      <th>83</th>
      <td>highlight common</td>
      <td>0.022552</td>
    </tr>
    <tr>
      <th>84</th>
      <td>remain limited systematize</td>
      <td>0.021874</td>
    </tr>
    <tr>
      <th>85</th>
      <td>augmentation utilization</td>
      <td>0.021778</td>
    </tr>
    <tr>
      <th>86</th>
      <td>accurate estimate</td>
      <td>0.021669</td>
    </tr>
    <tr>
      <th>87</th>
      <td>bypass strong</td>
      <td>0.021095</td>
    </tr>
    <tr>
      <th>88</th>
      <td>solution counter intuitive property</td>
      <td>0.020606</td>
    </tr>
    <tr>
      <th>89</th>
      <td>m wide</td>
      <td>0.020574</td>
    </tr>
    <tr>
      <th>90</th>
      <td>order avoid</td>
      <td>0.020328</td>
    </tr>
    <tr>
      <th>91</th>
      <td>define end discuss</td>
      <td>0.020139</td>
    </tr>
    <tr>
      <th>92</th>
      <td>average maximization operation</td>
      <td>0.019848</td>
    </tr>
    <tr>
      <th>93</th>
      <td>scale near</td>
      <td>0.019465</td>
    </tr>
    <tr>
      <th>94</th>
      <td>structural element</td>
      <td>0.019429</td>
    </tr>
    <tr>
      <th>95</th>
      <td>convex activation</td>
      <td>0.018924</td>
    </tr>
    <tr>
      <th>96</th>
      <td>iterative filtering</td>
      <td>0.018741</td>
    </tr>
    <tr>
      <th>97</th>
      <td>misclassification failure</td>
      <td>0.018683</td>
    </tr>
    <tr>
      <th>98</th>
      <td>interested deploying</td>
      <td>0.018629</td>
    </tr>
    <tr>
      <th>99</th>
      <td>broad deployment</td>
      <td>0.018595</td>
    </tr>
    <tr>
      <th>100</th>
      <td>capability solve</td>
      <td>0.018407</td>
    </tr>
    <tr>
      <th>101</th>
      <td>critically lacking</td>
      <td>0.018289</td>
    </tr>
    <tr>
      <th>102</th>
      <td>theoretical formulation</td>
      <td>0.018081</td>
    </tr>
    <tr>
      <th>103</th>
      <td>supervision supervised</td>
      <td>0.018070</td>
    </tr>
    <tr>
      <th>104</th>
      <td>prove extremely</td>
      <td>0.018033</td>
    </tr>
    <tr>
      <th>105</th>
      <td>iterate converge</td>
      <td>0.018017</td>
    </tr>
    <tr>
      <th>106</th>
      <td>perceptible completely</td>
      <td>0.017687</td>
    </tr>
    <tr>
      <th>107</th>
      <td>key insight</td>
      <td>0.017641</td>
    </tr>
    <tr>
      <th>108</th>
      <td>privacy need</td>
      <td>0.017399</td>
    </tr>
    <tr>
      <th>109</th>
      <td>signal camera</td>
      <td>0.016727</td>
    </tr>
    <tr>
      <th>110</th>
      <td>precisely abiliti</td>
      <td>0.016548</td>
    </tr>
    <tr>
      <th>111</th>
      <td>dnn recommend</td>
      <td>0.016507</td>
    </tr>
    <tr>
      <th>112</th>
      <td>open issue</td>
      <td>0.016480</td>
    </tr>
    <tr>
      <th>113</th>
      <td>review main threat</td>
      <td>0.016320</td>
    </tr>
    <tr>
      <th>114</th>
      <td>inherent weakness</td>
      <td>0.015680</td>
    </tr>
    <tr>
      <th>115</th>
      <td>reliable sense universal</td>
      <td>0.015513</td>
    </tr>
    <tr>
      <th>116</th>
      <td>attention autonomous driving community</td>
      <td>0.015434</td>
    </tr>
    <tr>
      <th>117</th>
      <td>involve rely</td>
      <td>0.015145</td>
    </tr>
    <tr>
      <th>118</th>
      <td>weight suppress</td>
      <td>0.014929</td>
    </tr>
    <tr>
      <th>119</th>
      <td>bind true</td>
      <td>0.014519</td>
    </tr>
    <tr>
      <th>120</th>
      <td>search latent</td>
      <td>0.014517</td>
    </tr>
    <tr>
      <th>121</th>
      <td>pool prior</td>
      <td>0.014427</td>
    </tr>
    <tr>
      <th>122</th>
      <td>related variant intrinsically</td>
      <td>0.014353</td>
    </tr>
    <tr>
      <th>123</th>
      <td>boundary fundamental</td>
      <td>0.014313</td>
    </tr>
    <tr>
      <th>124</th>
      <td>agnostic view</td>
      <td>0.014231</td>
    </tr>
    <tr>
      <th>125</th>
      <td>individually collectively</td>
      <td>0.013680</td>
    </tr>
    <tr>
      <th>126</th>
      <td>verification validation</td>
      <td>0.013487</td>
    </tr>
    <tr>
      <th>127</th>
      <td>pass verified</td>
      <td>0.013434</td>
    </tr>
    <tr>
      <th>128</th>
      <td>predictor verifi</td>
      <td>0.013431</td>
    </tr>
    <tr>
      <th>129</th>
      <td>interesting connection</td>
      <td>0.013403</td>
    </tr>
    <tr>
      <th>130</th>
      <td>spatial smoothing</td>
      <td>0.013375</td>
    </tr>
    <tr>
      <th>131</th>
      <td>dependency numerous</td>
      <td>0.013287</td>
    </tr>
    <tr>
      <th>132</th>
      <td>differentiable jointly</td>
      <td>0.013219</td>
    </tr>
    <tr>
      <th>133</th>
      <td>manner account</td>
      <td>0.013196</td>
    </tr>
    <tr>
      <th>134</th>
      <td>motivation constraint</td>
      <td>0.013081</td>
    </tr>
    <tr>
      <th>135</th>
      <td>renderer mislead</td>
      <td>0.012977</td>
    </tr>
    <tr>
      <th>136</th>
      <td>variation perception underlie</td>
      <td>0.012911</td>
    </tr>
    <tr>
      <th>137</th>
      <td>fast stable</td>
      <td>0.012891</td>
    </tr>
    <tr>
      <th>138</th>
      <td>provable convergence</td>
      <td>0.012753</td>
    </tr>
    <tr>
      <th>139</th>
      <td>date consider</td>
      <td>0.012410</td>
    </tr>
    <tr>
      <th>140</th>
      <td>drive car</td>
      <td>0.011986</td>
    </tr>
    <tr>
      <th>141</th>
      <td>quantitatively impact</td>
      <td>0.011940</td>
    </tr>
    <tr>
      <th>142</th>
      <td>contributing factor difficulty</td>
      <td>0.011637</td>
    </tr>
    <tr>
      <th>143</th>
      <td>sentence automatically</td>
      <td>0.011600</td>
    </tr>
    <tr>
      <th>144</th>
      <td>precision counterpart</td>
      <td>0.011545</td>
    </tr>
    <tr>
      <th>145</th>
      <td>theory explain</td>
      <td>0.011398</td>
    </tr>
    <tr>
      <th>146</th>
      <td>fully resistant</td>
      <td>0.011320</td>
    </tr>
    <tr>
      <th>147</th>
      <td>reasoning causal</td>
      <td>0.011295</td>
    </tr>
    <tr>
      <th>148</th>
      <td>edge device</td>
      <td>0.011165</td>
    </tr>
    <tr>
      <th>149</th>
      <td>degrade r</td>
      <td>0.011158</td>
    </tr>
    <tr>
      <th>150</th>
      <td>intent cause</td>
      <td>0.011066</td>
    </tr>
    <tr>
      <th>151</th>
      <td>guide intuition</td>
      <td>0.011063</td>
    </tr>
    <tr>
      <th>152</th>
      <td>mean tackle</td>
      <td>0.011031</td>
    </tr>
    <tr>
      <th>153</th>
      <td>help prevent</td>
      <td>0.011007</td>
    </tr>
    <tr>
      <th>154</th>
      <td>crop validate</td>
      <td>0.010880</td>
    </tr>
    <tr>
      <th>155</th>
      <td>area year start</td>
      <td>0.010637</td>
    </tr>
    <tr>
      <th>156</th>
      <td>topology pre</td>
      <td>0.010343</td>
    </tr>
    <tr>
      <th>157</th>
      <td>fine tune</td>
      <td>0.009930</td>
    </tr>
    <tr>
      <th>158</th>
      <td>generic flexible</td>
      <td>0.009790</td>
    </tr>
    <tr>
      <th>159</th>
      <td>parametrize explicitly</td>
      <td>0.009707</td>
    </tr>
    <tr>
      <th>160</th>
      <td>explicit parametrization</td>
      <td>0.009707</td>
    </tr>
    <tr>
      <th>161</th>
      <td>location category</td>
      <td>0.009542</td>
    </tr>
    <tr>
      <th>162</th>
      <td>identical rule</td>
      <td>0.009509</td>
    </tr>
    <tr>
      <th>163</th>
      <td>threshold advance</td>
      <td>0.009001</td>
    </tr>
    <tr>
      <th>164</th>
      <td>cross spectral</td>
      <td>0.008652</td>
    </tr>
    <tr>
      <th>165</th>
      <td>propagation fake</td>
      <td>0.008407</td>
    </tr>
    <tr>
      <th>166</th>
      <td>retrain recover</td>
      <td>0.008179</td>
    </tr>
    <tr>
      <th>167</th>
      <td>topological geometrical</td>
      <td>0.008160</td>
    </tr>
    <tr>
      <th>168</th>
      <td>artificial intelligence</td>
      <td>0.008039</td>
    </tr>
    <tr>
      <th>169</th>
      <td>indistinguishability act</td>
      <td>0.007845</td>
    </tr>
    <tr>
      <th>170</th>
      <td>nonlinearity overfitt</td>
      <td>0.007392</td>
    </tr>
    <tr>
      <th>171</th>
      <td>epsilon consume huge resource</td>
      <td>0.006824</td>
    </tr>
    <tr>
      <th>172</th>
      <td>leak excessive</td>
      <td>0.006562</td>
    </tr>
  </tbody>
</table><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Key Phrase: RAKE</th>
      <th>Score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>deep neural networks</td>
      <td>7.476131</td>
    </tr>
    <tr>
      <th>1</th>
      <td>convolutional neural networks</td>
      <td>7.456304</td>
    </tr>
    <tr>
      <th>2</th>
      <td>deep neural network</td>
      <td>7.229615</td>
    </tr>
    <tr>
      <th>3</th>
      <td>convolutional neural network</td>
      <td>7.209788</td>
    </tr>
    <tr>
      <th>4</th>
      <td>injecting adversarial examples</td>
      <td>7.136081</td>
    </tr>
    <tr>
      <th>5</th>
      <td>deep learning algorithms</td>
      <td>7.095566</td>
    </tr>
    <tr>
      <th>6</th>
      <td>deep learning models</td>
      <td>7.025462</td>
    </tr>
    <tr>
      <th>7</th>
      <td>deep learning systems</td>
      <td>6.966888</td>
    </tr>
    <tr>
      <th>8</th>
      <td>adversarial machine learning</td>
      <td>6.911027</td>
    </tr>
    <tr>
      <th>9</th>
      <td>experimental results show</td>
      <td>6.854601</td>
    </tr>
    <tr>
      <th>10</th>
      <td>machine learning algorithms</td>
      <td>6.848812</td>
    </tr>
    <tr>
      <th>11</th>
      <td>machine learning models</td>
      <td>6.778708</td>
    </tr>
    <tr>
      <th>12</th>
      <td>generative adversarial networks</td>
      <td>6.765760</td>
    </tr>
    <tr>
      <th>13</th>
      <td>machine learning tasks</td>
      <td>6.746450</td>
    </tr>
    <tr>
      <th>14</th>
      <td>machine learning systems</td>
      <td>6.720134</td>
    </tr>
    <tr>
      <th>15</th>
      <td>attack success rate</td>
      <td>6.678534</td>
    </tr>
    <tr>
      <th>16</th>
      <td>machine learning classifiers</td>
      <td>6.625644</td>
    </tr>
    <tr>
      <th>17</th>
      <td>recent studies show</td>
      <td>6.614621</td>
    </tr>
    <tr>
      <th>18</th>
      <td>machine learning model</td>
      <td>6.609588</td>
    </tr>
    <tr>
      <th>19</th>
      <td>generative adversarial network</td>
      <td>6.519244</td>
    </tr>
    <tr>
      <th>20</th>
      <td>box adversarial attacks</td>
      <td>6.429201</td>
    </tr>
    <tr>
      <th>21</th>
      <td>box threat models</td>
      <td>6.403453</td>
    </tr>
    <tr>
      <th>22</th>
      <td>generating adversarial examples</td>
      <td>6.399012</td>
    </tr>
    <tr>
      <th>23</th>
      <td>adversarial examples generated</td>
      <td>6.398067</td>
    </tr>
    <tr>
      <th>24</th>
      <td>computer vision tasks</td>
      <td>6.289231</td>
    </tr>
    <tr>
      <th>25</th>
      <td>box attack settings</td>
      <td>6.185356</td>
    </tr>
    <tr>
      <th>26</th>
      <td>detecting adversarial examples</td>
      <td>6.152973</td>
    </tr>
    <tr>
      <th>27</th>
      <td>generate adversarial examples</td>
      <td>6.132876</td>
    </tr>
    <tr>
      <th>28</th>
      <td>human visual system</td>
      <td>6.126068</td>
    </tr>
    <tr>
      <th>29</th>
      <td>conduct extensive experiments</td>
      <td>6.085855</td>
    </tr>
    <tr>
      <th>30</th>
      <td>image classification tasks</td>
      <td>5.998416</td>
    </tr>
    <tr>
      <th>31</th>
      <td>small adversarial perturbations</td>
      <td>5.990657</td>
    </tr>
    <tr>
      <th>32</th>
      <td>transferable adversarial examples</td>
      <td>5.948581</td>
    </tr>
    <tr>
      <th>33</th>
      <td>black box attacks</td>
      <td>5.676745</td>
    </tr>
    <tr>
      <th>34</th>
      <td>deep neural</td>
      <td>5.221615</td>
    </tr>
    <tr>
      <th>35</th>
      <td>convolutional neural</td>
      <td>5.201788</td>
    </tr>
    <tr>
      <th>36</th>
      <td>deep learning</td>
      <td>4.993204</td>
    </tr>
    <tr>
      <th>37</th>
      <td>deep networks</td>
      <td>4.897719</td>
    </tr>
    <tr>
      <th>38</th>
      <td>reinforcement learning</td>
      <td>4.883333</td>
    </tr>
    <tr>
      <th>39</th>
      <td>convolutional networks</td>
      <td>4.877892</td>
    </tr>
    <tr>
      <th>40</th>
      <td>neural networks</td>
      <td>4.832927</td>
    </tr>
    <tr>
      <th>41</th>
      <td>machine learning</td>
      <td>4.746450</td>
    </tr>
    <tr>
      <th>42</th>
      <td>success rate</td>
      <td>4.715956</td>
    </tr>
    <tr>
      <th>43</th>
      <td>deep models</td>
      <td>4.675462</td>
    </tr>
    <tr>
      <th>44</th>
      <td>stop sign</td>
      <td>4.660714</td>
    </tr>
    <tr>
      <th>45</th>
      <td>face recognition</td>
      <td>4.655601</td>
    </tr>
    <tr>
      <th>46</th>
      <td>deep network</td>
      <td>4.651204</td>
    </tr>
    <tr>
      <th>47</th>
      <td>jpeg compression</td>
      <td>4.646724</td>
    </tr>
    <tr>
      <th>48</th>
      <td>neural network</td>
      <td>4.586411</td>
    </tr>
    <tr>
      <th>49</th>
      <td>saak transform</td>
      <td>4.544444</td>
    </tr>
    <tr>
      <th>50</th>
      <td>deep architectures</td>
      <td>4.502579</td>
    </tr>
    <tr>
      <th>51</th>
      <td>data poisoning</td>
      <td>4.502332</td>
    </tr>
    <tr>
      <th>52</th>
      <td>supervised learning</td>
      <td>4.492857</td>
    </tr>
    <tr>
      <th>53</th>
      <td>experimental results</td>
      <td>4.490965</td>
    </tr>
    <tr>
      <th>54</th>
      <td>test data</td>
      <td>4.470249</td>
    </tr>
    <tr>
      <th>55</th>
      <td>results show</td>
      <td>4.468636</td>
    </tr>
    <tr>
      <th>56</th>
      <td>generative modeling</td>
      <td>4.464314</td>
    </tr>
    <tr>
      <th>57</th>
      <td>learning algorithms</td>
      <td>4.452362</td>
    </tr>
    <tr>
      <th>58</th>
      <td>computational cost</td>
      <td>4.447293</td>
    </tr>
    <tr>
      <th>59</th>
      <td>high confidence</td>
      <td>4.433667</td>
    </tr>
    <tr>
      <th>60</th>
      <td>adversarial networks</td>
      <td>4.419093</td>
    </tr>
    <tr>
      <th>61</th>
      <td>regularization term</td>
      <td>4.404040</td>
    </tr>
    <tr>
      <th>62</th>
      <td>speech recognition</td>
      <td>4.395694</td>
    </tr>
    <tr>
      <th>63</th>
      <td>driving cars</td>
      <td>4.393939</td>
    </tr>
    <tr>
      <th>64</th>
      <td>autonomous driving</td>
      <td>4.389435</td>
    </tr>
    <tr>
      <th>65</th>
      <td>carefully crafted</td>
      <td>4.385522</td>
    </tr>
    <tr>
      <th>66</th>
      <td>prior work</td>
      <td>4.382704</td>
    </tr>
    <tr>
      <th>67</th>
      <td>learning models</td>
      <td>4.382258</td>
    </tr>
    <tr>
      <th>68</th>
      <td>latent variables</td>
      <td>4.381818</td>
    </tr>
    <tr>
      <th>69</th>
      <td>art results</td>
      <td>4.377727</td>
    </tr>
    <tr>
      <th>70</th>
      <td>box scenario</td>
      <td>4.377463</td>
    </tr>
    <tr>
      <th>71</th>
      <td>recent work</td>
      <td>4.372057</td>
    </tr>
    <tr>
      <th>72</th>
      <td>processing step</td>
      <td>4.361672</td>
    </tr>
    <tr>
      <th>73</th>
      <td>current dnns</td>
      <td>4.361598</td>
    </tr>
    <tr>
      <th>74</th>
      <td>data augmentation</td>
      <td>4.360505</td>
    </tr>
    <tr>
      <th>75</th>
      <td>causal graph</td>
      <td>4.358289</td>
    </tr>
    <tr>
      <th>76</th>
      <td>3d objects</td>
      <td>4.354926</td>
    </tr>
    <tr>
      <th>77</th>
      <td>loss function</td>
      <td>4.338983</td>
    </tr>
    <tr>
      <th>78</th>
      <td>empirical evaluations</td>
      <td>4.333333</td>
    </tr>
    <tr>
      <th>79</th>
      <td>data samples</td>
      <td>4.332965</td>
    </tr>
    <tr>
      <th>80</th>
      <td>dnn models</td>
      <td>4.325362</td>
    </tr>
    <tr>
      <th>81</th>
      <td>learning systems</td>
      <td>4.323684</td>
    </tr>
    <tr>
      <th>82</th>
      <td>test time</td>
      <td>4.321282</td>
    </tr>
    <tr>
      <th>83</th>
      <td>training sets</td>
      <td>4.320413</td>
    </tr>
    <tr>
      <th>84</th>
      <td>sum game</td>
      <td>4.315789</td>
    </tr>
    <tr>
      <th>85</th>
      <td>step attacks</td>
      <td>4.314442</td>
    </tr>
    <tr>
      <th>86</th>
      <td>art models</td>
      <td>4.304985</td>
    </tr>
    <tr>
      <th>87</th>
      <td>box attack</td>
      <td>4.303003</td>
    </tr>
    <tr>
      <th>88</th>
      <td>make errors</td>
      <td>4.299020</td>
    </tr>
    <tr>
      <th>89</th>
      <td>computer vision</td>
      <td>4.289231</td>
    </tr>
    <tr>
      <th>90</th>
      <td>spatial transformation</td>
      <td>4.280952</td>
    </tr>
    <tr>
      <th>91</th>
      <td>lower bound</td>
      <td>4.280000</td>
    </tr>
    <tr>
      <th>92</th>
      <td>impressive performance</td>
      <td>4.272947</td>
    </tr>
    <tr>
      <th>93</th>
      <td>object detection</td>
      <td>4.267267</td>
    </tr>
    <tr>
      <th>94</th>
      <td>box attacks</td>
      <td>4.264624</td>
    </tr>
    <tr>
      <th>95</th>
      <td>adversarial examples</td>
      <td>4.261081</td>
    </tr>
    <tr>
      <th>96</th>
      <td>latent space</td>
      <td>4.260870</td>
    </tr>
    <tr>
      <th>97</th>
      <td>art methods</td>
      <td>4.259394</td>
    </tr>
    <tr>
      <th>98</th>
      <td>recent studies</td>
      <td>4.250985</td>
    </tr>
    <tr>
      <th>99</th>
      <td>real world</td>
      <td>4.240741</td>
    </tr>
    <tr>
      <th>100</th>
      <td>upper bound</td>
      <td>4.235294</td>
    </tr>
    <tr>
      <th>101</th>
      <td>physical world</td>
      <td>4.234788</td>
    </tr>
    <tr>
      <th>102</th>
      <td>federated learning</td>
      <td>4.225000</td>
    </tr>
    <tr>
      <th>103</th>
      <td>box settings</td>
      <td>4.222778</td>
    </tr>
    <tr>
      <th>104</th>
      <td>feature space</td>
      <td>4.219406</td>
    </tr>
    <tr>
      <th>105</th>
      <td>training data</td>
      <td>4.219380</td>
    </tr>
    <tr>
      <th>106</th>
      <td>data manifold</td>
      <td>4.218365</td>
    </tr>
    <tr>
      <th>107</th>
      <td>adversarial samples</td>
      <td>4.213960</td>
    </tr>
    <tr>
      <th>108</th>
      <td>learning process</td>
      <td>4.213636</td>
    </tr>
    <tr>
      <th>109</th>
      <td>human vision</td>
      <td>4.211966</td>
    </tr>
    <tr>
      <th>110</th>
      <td>generative model</td>
      <td>4.209805</td>
    </tr>
    <tr>
      <th>111</th>
      <td>theoretical analysis</td>
      <td>4.207437</td>
    </tr>
    <tr>
      <th>112</th>
      <td>box model</td>
      <td>4.203564</td>
    </tr>
    <tr>
      <th>113</th>
      <td>art attacks</td>
      <td>4.196926</td>
    </tr>
    <tr>
      <th>114</th>
      <td>inference time</td>
      <td>4.193439</td>
    </tr>
    <tr>
      <th>115</th>
      <td>current methods</td>
      <td>4.190370</td>
    </tr>
    <tr>
      <th>116</th>
      <td>poisoning attack</td>
      <td>4.181328</td>
    </tr>
    <tr>
      <th>117</th>
      <td>input data</td>
      <td>4.176302</td>
    </tr>
    <tr>
      <th>118</th>
      <td>box setting</td>
      <td>4.173759</td>
    </tr>
    <tr>
      <th>119</th>
      <td>previous work</td>
      <td>4.173703</td>
    </tr>
    <tr>
      <th>120</th>
      <td>malicious perturbations</td>
      <td>4.173273</td>
    </tr>
    <tr>
      <th>121</th>
      <td>adversarial image</td>
      <td>4.166657</td>
    </tr>
    <tr>
      <th>122</th>
      <td>training set</td>
      <td>4.166567</td>
    </tr>
    <tr>
      <th>123</th>
      <td>adversarial domain</td>
      <td>4.164578</td>
    </tr>
    <tr>
      <th>124</th>
      <td>data points</td>
      <td>4.162370</td>
    </tr>
    <tr>
      <th>125</th>
      <td>defense mechanism</td>
      <td>4.161964</td>
    </tr>
    <tr>
      <th>126</th>
      <td>empirically show</td>
      <td>4.159091</td>
    </tr>
    <tr>
      <th>127</th>
      <td>show empirically</td>
      <td>4.159091</td>
    </tr>
    <tr>
      <th>128</th>
      <td>dnn model</td>
      <td>4.156242</td>
    </tr>
    <tr>
      <th>129</th>
      <td>2d images</td>
      <td>4.149003</td>
    </tr>
    <tr>
      <th>130</th>
      <td>poisoning attacks</td>
      <td>4.142948</td>
    </tr>
    <tr>
      <th>131</th>
      <td>recognition systems</td>
      <td>4.142105</td>
    </tr>
    <tr>
      <th>132</th>
      <td>existing methods</td>
      <td>4.141306</td>
    </tr>
    <tr>
      <th>133</th>
      <td>experiments show</td>
      <td>4.139147</td>
    </tr>
    <tr>
      <th>134</th>
      <td>adversarial attack</td>
      <td>4.127156</td>
    </tr>
    <tr>
      <th>135</th>
      <td>data distribution</td>
      <td>4.126102</td>
    </tr>
    <tr>
      <th>136</th>
      <td>box scenarios</td>
      <td>4.124209</td>
    </tr>
    <tr>
      <th>137</th>
      <td>original image</td>
      <td>4.122958</td>
    </tr>
    <tr>
      <th>138</th>
      <td>attack strategies</td>
      <td>4.118134</td>
    </tr>
    <tr>
      <th>139</th>
      <td>adversarial noise</td>
      <td>4.114578</td>
    </tr>
    <tr>
      <th>140</th>
      <td>adversarial training</td>
      <td>4.100375</td>
    </tr>
    <tr>
      <th>141</th>
      <td>high accuracy</td>
      <td>4.098523</td>
    </tr>
    <tr>
      <th>142</th>
      <td>true label</td>
      <td>4.097222</td>
    </tr>
    <tr>
      <th>143</th>
      <td>learned models</td>
      <td>4.092258</td>
    </tr>
    <tr>
      <th>144</th>
      <td>visual quality</td>
      <td>4.092105</td>
    </tr>
    <tr>
      <th>145</th>
      <td>semantic segmentation</td>
      <td>4.090703</td>
    </tr>
    <tr>
      <th>146</th>
      <td>adversarial attacks</td>
      <td>4.088776</td>
    </tr>
    <tr>
      <th>147</th>
      <td>extensive experiments</td>
      <td>4.085855</td>
    </tr>
    <tr>
      <th>148</th>
      <td>recent research</td>
      <td>4.085343</td>
    </tr>
    <tr>
      <th>149</th>
      <td>physical attacks</td>
      <td>4.084913</td>
    </tr>
    <tr>
      <th>150</th>
      <td>easily fool</td>
      <td>4.084821</td>
    </tr>
    <tr>
      <th>151</th>
      <td>natural examples</td>
      <td>4.084158</td>
    </tr>
    <tr>
      <th>152</th>
      <td>gradient masking</td>
      <td>4.083333</td>
    </tr>
    <tr>
      <th>153</th>
      <td>recent works</td>
      <td>4.078159</td>
    </tr>
    <tr>
      <th>154</th>
      <td>networks trained</td>
      <td>4.077771</td>
    </tr>
    <tr>
      <th>155</th>
      <td>distribution set</td>
      <td>4.073289</td>
    </tr>
    <tr>
      <th>156</th>
      <td>adversarial perturbations</td>
      <td>4.067580</td>
    </tr>
    <tr>
      <th>157</th>
      <td>attack algorithms</td>
      <td>4.064940</td>
    </tr>
    <tr>
      <th>158</th>
      <td>point clouds</td>
      <td>4.063492</td>
    </tr>
    <tr>
      <th>159</th>
      <td>threat models</td>
      <td>4.063027</td>
    </tr>
    <tr>
      <th>160</th>
      <td>image space</td>
      <td>4.062949</td>
    </tr>
    <tr>
      <th>161</th>
      <td>target models</td>
      <td>4.062792</td>
    </tr>
    <tr>
      <th>162</th>
      <td>defense techniques</td>
      <td>4.059199</td>
    </tr>
    <tr>
      <th>163</th>
      <td>adversarially trained</td>
      <td>4.056589</td>
    </tr>
    <tr>
      <th>164</th>
      <td>iterative attacks</td>
      <td>4.054633</td>
    </tr>
    <tr>
      <th>165</th>
      <td>adversarial regions</td>
      <td>4.053467</td>
    </tr>
    <tr>
      <th>166</th>
      <td>previous studies</td>
      <td>4.052632</td>
    </tr>
    <tr>
      <th>167</th>
      <td>annotated images</td>
      <td>4.049003</td>
    </tr>
    <tr>
      <th>168</th>
      <td>mutual information</td>
      <td>4.048518</td>
    </tr>
    <tr>
      <th>169</th>
      <td>adversarial settings</td>
      <td>4.046931</td>
    </tr>
    <tr>
      <th>170</th>
      <td>multiple attacks</td>
      <td>4.046647</td>
    </tr>
    <tr>
      <th>171</th>
      <td>art performance</td>
      <td>4.045674</td>
    </tr>
    <tr>
      <th>172</th>
      <td>objective function</td>
      <td>4.045530</td>
    </tr>
    <tr>
      <th>173</th>
      <td>perturbed images</td>
      <td>4.044655</td>
    </tr>
    <tr>
      <th>174</th>
      <td>human eye</td>
      <td>4.042735</td>
    </tr>
    <tr>
      <th>175</th>
      <td>human eyes</td>
      <td>4.042735</td>
    </tr>
    <tr>
      <th>176</th>
      <td>defensive distillation</td>
      <td>4.039855</td>
    </tr>
    <tr>
      <th>177</th>
      <td>activation functions</td>
      <td>4.039702</td>
    </tr>
    <tr>
      <th>178</th>
      <td>universal perturbations</td>
      <td>4.032632</td>
    </tr>
    <tr>
      <th>179</th>
      <td>target image</td>
      <td>4.032613</td>
    </tr>
    <tr>
      <th>180</th>
      <td>defense methods</td>
      <td>4.032352</td>
    </tr>
    <tr>
      <th>181</th>
      <td>object detectors</td>
      <td>4.018018</td>
    </tr>
    <tr>
      <th>182</th>
      <td>real images</td>
      <td>4.015670</td>
    </tr>
    <tr>
      <th>183</th>
      <td>adversarial images</td>
      <td>4.013581</td>
    </tr>
    <tr>
      <th>184</th>
      <td>adversarial perturbation</td>
      <td>4.009172</td>
    </tr>
    <tr>
      <th>185</th>
      <td>defended networks</td>
      <td>4.004516</td>
    </tr>
    <tr>
      <th>186</th>
      <td>random noise</td>
      <td>4.002632</td>
    </tr>
    <tr>
      <th>187</th>
      <td>image classification</td>
      <td>3.998416</td>
    </tr>
    <tr>
      <th>188</th>
      <td>defense strategy</td>
      <td>3.998066</td>
    </tr>
    <tr>
      <th>189</th>
      <td>classification tasks</td>
      <td>3.996337</td>
    </tr>
    <tr>
      <th>190</th>
      <td>critical systems</td>
      <td>3.991866</td>
    </tr>
    <tr>
      <th>191</th>
      <td>input examples</td>
      <td>3.989224</td>
    </tr>
    <tr>
      <th>192</th>
      <td>training samples</td>
      <td>3.985180</td>
    </tr>
    <tr>
      <th>193</th>
      <td>adversarial subspaces</td>
      <td>3.982759</td>
    </tr>
    <tr>
      <th>194</th>
      <td>classification problems</td>
      <td>3.976337</td>
    </tr>
    <tr>
      <th>195</th>
      <td>autonomous vehicles</td>
      <td>3.974662</td>
    </tr>
    <tr>
      <th>196</th>
      <td>multiscale processing</td>
      <td>3.971429</td>
    </tr>
    <tr>
      <th>197</th>
      <td>original images</td>
      <td>3.969882</td>
    </tr>
    <tr>
      <th>198</th>
      <td>video frames</td>
      <td>3.965630</td>
    </tr>
    <tr>
      <th>199</th>
      <td>successfully attack</td>
      <td>3.962578</td>
    </tr>
    <tr>
      <th>200</th>
      <td>based models</td>
      <td>3.958065</td>
    </tr>
    <tr>
      <th>201</th>
      <td>detection method</td>
      <td>3.955988</td>
    </tr>
    <tr>
      <th>202</th>
      <td>random perturbations</td>
      <td>3.955634</td>
    </tr>
    <tr>
      <th>203</th>
      <td>backdoor attacks</td>
      <td>3.955448</td>
    </tr>
    <tr>
      <th>204</th>
      <td>clean examples</td>
      <td>3.953646</td>
    </tr>
    <tr>
      <th>205</th>
      <td>input space</td>
      <td>3.953590</td>
    </tr>
    <tr>
      <th>206</th>
      <td>previous methods</td>
      <td>3.951579</td>
    </tr>
    <tr>
      <th>207</th>
      <td>hidden layers</td>
      <td>3.950549</td>
    </tr>
    <tr>
      <th>208</th>
      <td>visual concepts</td>
      <td>3.950000</td>
    </tr>
    <tr>
      <th>209</th>
      <td>attack methods</td>
      <td>3.949245</td>
    </tr>
    <tr>
      <th>210</th>
      <td>benign examples</td>
      <td>3.946503</td>
    </tr>
    <tr>
      <th>211</th>
      <td>perceptual similarity</td>
      <td>3.937500</td>
    </tr>
    <tr>
      <th>212</th>
      <td>defense mechanisms</td>
      <td>3.934574</td>
    </tr>
    <tr>
      <th>213</th>
      <td>art defenses</td>
      <td>3.930622</td>
    </tr>
    <tr>
      <th>214</th>
      <td>representative natural</td>
      <td>3.925154</td>
    </tr>
    <tr>
      <th>215</th>
      <td>evasion attacks</td>
      <td>3.924198</td>
    </tr>
    <tr>
      <th>216</th>
      <td>learned model</td>
      <td>3.923139</td>
    </tr>
    <tr>
      <th>217</th>
      <td>malware detection</td>
      <td>3.922222</td>
    </tr>
    <tr>
      <th>218</th>
      <td>target label</td>
      <td>3.919423</td>
    </tr>
    <tr>
      <th>219</th>
      <td>clean samples</td>
      <td>3.906526</td>
    </tr>
    <tr>
      <th>220</th>
      <td>boundary attack</td>
      <td>3.905435</td>
    </tr>
    <tr>
      <th>221</th>
      <td>final layer</td>
      <td>3.905376</td>
    </tr>
    <tr>
      <th>222</th>
      <td>results suggest</td>
      <td>3.905000</td>
    </tr>
    <tr>
      <th>223</th>
      <td>input image</td>
      <td>3.894799</td>
    </tr>
    <tr>
      <th>224</th>
      <td>threat model</td>
      <td>3.893908</td>
    </tr>
    <tr>
      <th>225</th>
      <td>target model</td>
      <td>3.893673</td>
    </tr>
    <tr>
      <th>226</th>
      <td>distribution samples</td>
      <td>3.891902</td>
    </tr>
    <tr>
      <th>227</th>
      <td>image regions</td>
      <td>3.890968</td>
    </tr>
    <tr>
      <th>228</th>
      <td>training procedure</td>
      <td>3.890343</td>
    </tr>
    <tr>
      <th>229</th>
      <td>based attack</td>
      <td>3.888384</td>
    </tr>
    <tr>
      <th>230</th>
      <td>training dataset</td>
      <td>3.883166</td>
    </tr>
    <tr>
      <th>231</th>
      <td>image classifiers</td>
      <td>3.881274</td>
    </tr>
    <tr>
      <th>232</th>
      <td>test accuracy</td>
      <td>3.880934</td>
    </tr>
    <tr>
      <th>233</th>
      <td>previous works</td>
      <td>3.879806</td>
    </tr>
    <tr>
      <th>234</th>
      <td>network architectures</td>
      <td>3.867375</td>
    </tr>
    <tr>
      <th>235</th>
      <td>pixel space</td>
      <td>3.864791</td>
    </tr>
    <tr>
      <th>236</th>
      <td>underlying model</td>
      <td>3.863139</td>
    </tr>
    <tr>
      <th>237</th>
      <td>trained models</td>
      <td>3.855514</td>
    </tr>
    <tr>
      <th>238</th>
      <td>models trained</td>
      <td>3.855514</td>
    </tr>
    <tr>
      <th>239</th>
      <td>based attacks</td>
      <td>3.850005</td>
    </tr>
    <tr>
      <th>240</th>
      <td>adversarial inputs</td>
      <td>3.841997</td>
    </tr>
    <tr>
      <th>241</th>
      <td>large margin</td>
      <td>3.841848</td>
    </tr>
    <tr>
      <th>242</th>
      <td>natural images</td>
      <td>3.836657</td>
    </tr>
    <tr>
      <th>243</th>
      <td>social media</td>
      <td>3.833333</td>
    </tr>
    <tr>
      <th>244</th>
      <td>trained network</td>
      <td>3.831256</td>
    </tr>
    <tr>
      <th>245</th>
      <td>recent years</td>
      <td>3.829932</td>
    </tr>
    <tr>
      <th>246</th>
      <td>classified incorrectly</td>
      <td>3.826087</td>
    </tr>
    <tr>
      <th>247</th>
      <td>small perturbations</td>
      <td>3.826079</td>
    </tr>
    <tr>
      <th>248</th>
      <td>adding small</td>
      <td>3.820513</td>
    </tr>
    <tr>
      <th>249</th>
      <td>wide range</td>
      <td>3.802900</td>
    </tr>
    <tr>
      <th>250</th>
      <td>training process</td>
      <td>3.799434</td>
    </tr>
    <tr>
      <th>251</th>
      <td>targeted attacks</td>
      <td>3.799198</td>
    </tr>
    <tr>
      <th>252</th>
      <td>original inputs</td>
      <td>3.798298</td>
    </tr>
    <tr>
      <th>253</th>
      <td>target class</td>
      <td>3.793246</td>
    </tr>
    <tr>
      <th>254</th>
      <td>obfuscated gradients</td>
      <td>3.789474</td>
    </tr>
    <tr>
      <th>255</th>
      <td>art robustness</td>
      <td>3.787081</td>
    </tr>
    <tr>
      <th>256</th>
      <td>input features</td>
      <td>3.785577</td>
    </tr>
    <tr>
      <th>257</th>
      <td>open problem</td>
      <td>3.782609</td>
    </tr>
    <tr>
      <th>258</th>
      <td>training distribution</td>
      <td>3.778317</td>
    </tr>
    <tr>
      <th>259</th>
      <td>classification performance</td>
      <td>3.769284</td>
    </tr>
    <tr>
      <th>260</th>
      <td>critical applications</td>
      <td>3.768182</td>
    </tr>
    <tr>
      <th>261</th>
      <td>small perturbation</td>
      <td>3.767672</td>
    </tr>
    <tr>
      <th>262</th>
      <td>decision boundary</td>
      <td>3.765438</td>
    </tr>
    <tr>
      <th>263</th>
      <td>based system</td>
      <td>3.759140</td>
    </tr>
    <tr>
      <th>264</th>
      <td>decision boundaries</td>
      <td>3.755914</td>
    </tr>
    <tr>
      <th>265</th>
      <td>target person</td>
      <td>3.744820</td>
    </tr>
    <tr>
      <th>266</th>
      <td>input images</td>
      <td>3.741723</td>
    </tr>
    <tr>
      <th>267</th>
      <td>image transformations</td>
      <td>3.711756</td>
    </tr>
    <tr>
      <th>268</th>
      <td>clean images</td>
      <td>3.706146</td>
    </tr>
    <tr>
      <th>269</th>
      <td>model distribution</td>
      <td>3.705658</td>
    </tr>
    <tr>
      <th>270</th>
      <td>large datasets</td>
      <td>3.704348</td>
    </tr>
    <tr>
      <th>271</th>
      <td>large margins</td>
      <td>3.704348</td>
    </tr>
    <tr>
      <th>272</th>
      <td>benchmark datasets</td>
      <td>3.694737</td>
    </tr>
    <tr>
      <th>273</th>
      <td>security concerns</td>
      <td>3.692391</td>
    </tr>
    <tr>
      <th>274</th>
      <td>classification accuracy</td>
      <td>3.690605</td>
    </tr>
    <tr>
      <th>275</th>
      <td>trained model</td>
      <td>3.686395</td>
    </tr>
    <tr>
      <th>276</th>
      <td>art black</td>
      <td>3.684848</td>
    </tr>
    <tr>
      <th>277</th>
      <td>adversarial robustness</td>
      <td>3.678932</td>
    </tr>
    <tr>
      <th>278</th>
      <td>human perception</td>
      <td>3.674314</td>
    </tr>
    <tr>
      <th>279</th>
      <td>differential privacy</td>
      <td>3.669960</td>
    </tr>
    <tr>
      <th>280</th>
      <td>prior knowledge</td>
      <td>3.641446</td>
    </tr>
    <tr>
      <th>281</th>
      <td>facial attributes</td>
      <td>3.625000</td>
    </tr>
    <tr>
      <th>282</th>
      <td>recent advances</td>
      <td>3.617811</td>
    </tr>
    <tr>
      <th>283</th>
      <td>agnostic perturbations</td>
      <td>3.581574</td>
    </tr>
    <tr>
      <th>284</th>
      <td>imperceptible perturbations</td>
      <td>3.578678</td>
    </tr>
    <tr>
      <th>285</th>
      <td>existing black</td>
      <td>3.566760</td>
    </tr>
    <tr>
      <th>286</th>
      <td>ensemble methods</td>
      <td>3.566667</td>
    </tr>
    <tr>
      <th>287</th>
      <td>proposed method</td>
      <td>3.548421</td>
    </tr>
    <tr>
      <th>288</th>
      <td>general framework</td>
      <td>3.548276</td>
    </tr>
    <tr>
      <th>289</th>
      <td>saddle points</td>
      <td>3.545455</td>
    </tr>
    <tr>
      <th>290</th>
      <td>results demonstrate</td>
      <td>3.541782</td>
    </tr>
    <tr>
      <th>291</th>
      <td>robust features</td>
      <td>3.539916</td>
    </tr>
    <tr>
      <th>292</th>
      <td>classifier network</td>
      <td>3.535950</td>
    </tr>
    <tr>
      <th>293</th>
      <td>image classifier</td>
      <td>3.530029</td>
    </tr>
    <tr>
      <th>294</th>
      <td>proposed algorithm</td>
      <td>3.522202</td>
    </tr>
    <tr>
      <th>295</th>
      <td>significantly improve</td>
      <td>3.514310</td>
    </tr>
    <tr>
      <th>296</th>
      <td>mislead dnns</td>
      <td>3.505721</td>
    </tr>
    <tr>
      <th>297</th>
      <td>model architecture</td>
      <td>3.488139</td>
    </tr>
    <tr>
      <th>298</th>
      <td>current state</td>
      <td>3.480563</td>
    </tr>
    <tr>
      <th>299</th>
      <td>highly susceptible</td>
      <td>3.461905</td>
    </tr>
    <tr>
      <th>300</th>
      <td>small subset</td>
      <td>3.452489</td>
    </tr>
    <tr>
      <th>301</th>
      <td>knowledge distillation</td>
      <td>3.424054</td>
    </tr>
    <tr>
      <th>302</th>
      <td>optimization problem</td>
      <td>3.416894</td>
    </tr>
    <tr>
      <th>303</th>
      <td>wide variety</td>
      <td>3.393171</td>
    </tr>
    <tr>
      <th>304</th>
      <td>imagenet datasets</td>
      <td>3.386957</td>
    </tr>
    <tr>
      <th>305</th>
      <td>small number</td>
      <td>3.377622</td>
    </tr>
    <tr>
      <th>306</th>
      <td>model robustness</td>
      <td>3.377493</td>
    </tr>
    <tr>
      <th>307</th>
      <td>proposed approach</td>
      <td>3.361825</td>
    </tr>
    <tr>
      <th>308</th>
      <td>trained classifier</td>
      <td>3.351206</td>
    </tr>
    <tr>
      <th>309</th>
      <td>effective method</td>
      <td>3.350589</td>
    </tr>
    <tr>
      <th>310</th>
      <td>outperforms state</td>
      <td>3.348288</td>
    </tr>
    <tr>
      <th>311</th>
      <td>paper proposes</td>
      <td>3.313860</td>
    </tr>
    <tr>
      <th>312</th>
      <td>safety concerns</td>
      <td>3.291667</td>
    </tr>
    <tr>
      <th>313</th>
      <td>model parameters</td>
      <td>3.263139</td>
    </tr>
    <tr>
      <th>314</th>
      <td>mnist dataset</td>
      <td>3.261418</td>
    </tr>
    <tr>
      <th>315</th>
      <td>variational autoencoder</td>
      <td>3.250000</td>
    </tr>
    <tr>
      <th>316</th>
      <td>easily fooled</td>
      <td>3.232143</td>
    </tr>
    <tr>
      <th>317</th>
      <td>experiments demonstrate</td>
      <td>3.212292</td>
    </tr>
    <tr>
      <th>318</th>
      <td>limited number</td>
      <td>3.204545</td>
    </tr>
    <tr>
      <th>319</th>
      <td>experiments conducted</td>
      <td>3.204082</td>
    </tr>
    <tr>
      <th>320</th>
      <td>cifar10 datasets</td>
      <td>3.192857</td>
    </tr>
    <tr>
      <th>321</th>
      <td>achieved state</td>
      <td>3.187971</td>
    </tr>
    <tr>
      <th>322</th>
      <td>highly vulnerable</td>
      <td>3.187179</td>
    </tr>
    <tr>
      <th>323</th>
      <td>achieving state</td>
      <td>3.151860</td>
    </tr>
    <tr>
      <th>324</th>
      <td>paper presents</td>
      <td>3.140249</td>
    </tr>
    <tr>
      <th>325</th>
      <td>improve robustness</td>
      <td>2.991627</td>
    </tr>
    <tr>
      <th>326</th>
      <td>achieve state</td>
      <td>2.991145</td>
    </tr>
    <tr>
      <th>327</th>
      <td>paper focuses</td>
      <td>2.980527</td>
    </tr>
    <tr>
      <th>328</th>
      <td>widely applied</td>
      <td>2.691860</td>
    </tr>
    <tr>
      <th>329</th>
      <td>10 datasets</td>
      <td>1.800000</td>
    </tr>
  </tbody>
</table></body>
</html>