Certifiable Distributional Robustness with Principled Adversarial Training
Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality
Evaluating the Robustness of Neural Networks: An Extreme Value Theory Approach
Certified Defenses against Adversarial Examples
PixelDefend: Leveraging Generative Models to Understand and Defend against Adversarial Examples
Attacking Binarized Neural Networks
Towards Deep Learning Models Resistant to Adversarial Attacks
Defense-GAN: Protecting Classifiers Against Adversarial Attacks Using Generative Models
Mitigating Adversarial Effects Through Randomization
Countering Adversarial Images using Input Transformations
Generating Natural Adversarial Examples
Thermometer Encoding: One Hot Way To Resist Adversarial Examples
Ensemble Adversarial Training: Attacks and Defenses
Sensitivity and Generalization in Neural Networks
Cascade Adversarial Machine Learning Regularized with a Unified Embedding
Intriguing Properties of Adversarial Examples
MACHINE VS MACHINE: DEFENDING CLASSIFIERS AGAINST LEARNING-BASED ADVERSARIAL ATTACKS
Ensemble Methods as a Defense to Adversarial Perturbations Against Deep Neural Networks
Towards Safe Deep Learning: Unsupervised Defense Against Generic Adversarial Attacks
Universality, Robustness, and Detectability of Adversarial Perturbations under Adversarial Training
Unsupervised Adversarial Anomaly  Detection using One-Class Support Vector Machines
What are image captions made of?
TOWARDS SAFE DEEP LEARNING: UNSUPERVISED DEFENSE AGAINST GENERIC ADVERSARIAL ATTACKS
Deep Hyperspherical Defense against Adversarial Perturbations