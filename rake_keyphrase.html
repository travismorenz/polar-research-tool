<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Key Phrase</th>
      <th>Score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>deep neural networks</td>
      <td>7.460102</td>
    </tr>
    <tr>
      <th>1</th>
      <td>convolutional neural networks</td>
      <td>7.451786</td>
    </tr>
    <tr>
      <th>2</th>
      <td>deep neural network</td>
      <td>7.181331</td>
    </tr>
    <tr>
      <th>3</th>
      <td>convolutional neural network</td>
      <td>7.173015</td>
    </tr>
    <tr>
      <th>4</th>
      <td>deep learning algorithms</td>
      <td>7.099065</td>
    </tr>
    <tr>
      <th>5</th>
      <td>deep learning models</td>
      <td>7.042191</td>
    </tr>
    <tr>
      <th>6</th>
      <td>deep learning systems</td>
      <td>6.937526</td>
    </tr>
    <tr>
      <th>7</th>
      <td>adversarial machine learning</td>
      <td>6.890582</td>
    </tr>
    <tr>
      <th>8</th>
      <td>machine learning algorithms</td>
      <td>6.837481</td>
    </tr>
    <tr>
      <th>9</th>
      <td>experimental results show</td>
      <td>6.808140</td>
    </tr>
    <tr>
      <th>10</th>
      <td>machine learning models</td>
      <td>6.780608</td>
    </tr>
    <tr>
      <th>11</th>
      <td>generative adversarial networks</td>
      <td>6.749343</td>
    </tr>
    <tr>
      <th>12</th>
      <td>machine learning systems</td>
      <td>6.675942</td>
    </tr>
    <tr>
      <th>13</th>
      <td>attack success rate</td>
      <td>6.650058</td>
    </tr>
    <tr>
      <th>14</th>
      <td>recent studies show</td>
      <td>6.629230</td>
    </tr>
    <tr>
      <th>15</th>
      <td>machine learning model</td>
      <td>6.602866</td>
    </tr>
    <tr>
      <th>16</th>
      <td>generative adversarial network</td>
      <td>6.470572</td>
    </tr>
    <tr>
      <th>17</th>
      <td>adversarial examples generated</td>
      <td>6.453172</td>
    </tr>
    <tr>
      <th>18</th>
      <td>box adversarial attacks</td>
      <td>6.371217</td>
    </tr>
    <tr>
      <th>19</th>
      <td>generating adversarial examples</td>
      <td>6.360057</td>
    </tr>
    <tr>
      <th>20</th>
      <td>computer vision tasks</td>
      <td>6.247840</td>
    </tr>
    <tr>
      <th>21</th>
      <td>box attack settings</td>
      <td>6.116820</td>
    </tr>
    <tr>
      <th>22</th>
      <td>human visual system</td>
      <td>6.108832</td>
    </tr>
    <tr>
      <th>23</th>
      <td>generate adversarial examples</td>
      <td>6.095320</td>
    </tr>
    <tr>
      <th>24</th>
      <td>conduct extensive experiments</td>
      <td>6.067600</td>
    </tr>
    <tr>
      <th>25</th>
      <td>detecting adversarial examples</td>
      <td>6.063587</td>
    </tr>
    <tr>
      <th>26</th>
      <td>transferable adversarial examples</td>
      <td>5.973391</td>
    </tr>
    <tr>
      <th>27</th>
      <td>small adversarial perturbations</td>
      <td>5.962941</td>
    </tr>
    <tr>
      <th>28</th>
      <td>image classification tasks</td>
      <td>5.949163</td>
    </tr>
    <tr>
      <th>29</th>
      <td>black box attacks</td>
      <td>5.649771</td>
    </tr>
    <tr>
      <th>30</th>
      <td>deep neural</td>
      <td>5.203483</td>
    </tr>
    <tr>
      <th>31</th>
      <td>convolutional neural</td>
      <td>5.195167</td>
    </tr>
    <tr>
      <th>32</th>
      <td>deep learning</td>
      <td>4.999065</td>
    </tr>
    <tr>
      <th>33</th>
      <td>deep networks</td>
      <td>4.897288</td>
    </tr>
    <tr>
      <th>34</th>
      <td>convolutional networks</td>
      <td>4.888972</td>
    </tr>
    <tr>
      <th>35</th>
      <td>reinforcement learning</td>
      <td>4.858396</td>
    </tr>
    <tr>
      <th>36</th>
      <td>neural networks</td>
      <td>4.819433</td>
    </tr>
    <tr>
      <th>37</th>
      <td>machine learning</td>
      <td>4.737481</td>
    </tr>
    <tr>
      <th>38</th>
      <td>success rate</td>
      <td>4.708452</td>
    </tr>
    <tr>
      <th>39</th>
      <td>deep models</td>
      <td>4.683795</td>
    </tr>
    <tr>
      <th>40</th>
      <td>stop sign</td>
      <td>4.675000</td>
    </tr>
    <tr>
      <th>41</th>
      <td>jpeg compression</td>
      <td>4.646724</td>
    </tr>
    <tr>
      <th>42</th>
      <td>face recognition</td>
      <td>4.634831</td>
    </tr>
    <tr>
      <th>43</th>
      <td>deep network</td>
      <td>4.618517</td>
    </tr>
    <tr>
      <th>44</th>
      <td>supervised learning</td>
      <td>4.542607</td>
    </tr>
    <tr>
      <th>45</th>
      <td>neural network</td>
      <td>4.540662</td>
    </tr>
    <tr>
      <th>46</th>
      <td>deep architectures</td>
      <td>4.515669</td>
    </tr>
    <tr>
      <th>47</th>
      <td>data poisoning</td>
      <td>4.502961</td>
    </tr>
    <tr>
      <th>48</th>
      <td>saak transform</td>
      <td>4.497076</td>
    </tr>
    <tr>
      <th>49</th>
      <td>test data</td>
      <td>4.487109</td>
    </tr>
    <tr>
      <th>50</th>
      <td>learning algorithms</td>
      <td>4.458396</td>
    </tr>
    <tr>
      <th>51</th>
      <td>driving cars</td>
      <td>4.450000</td>
    </tr>
    <tr>
      <th>52</th>
      <td>results show</td>
      <td>4.446437</td>
    </tr>
    <tr>
      <th>53</th>
      <td>experimental results</td>
      <td>4.429499</td>
    </tr>
    <tr>
      <th>54</th>
      <td>carefully crafted</td>
      <td>4.409091</td>
    </tr>
    <tr>
      <th>55</th>
      <td>current dnns</td>
      <td>4.407708</td>
    </tr>
    <tr>
      <th>56</th>
      <td>learning models</td>
      <td>4.401523</td>
    </tr>
    <tr>
      <th>57</th>
      <td>box scenario</td>
      <td>4.401059</td>
    </tr>
    <tr>
      <th>58</th>
      <td>3d objects</td>
      <td>4.398535</td>
    </tr>
    <tr>
      <th>59</th>
      <td>autonomous driving</td>
      <td>4.388889</td>
    </tr>
    <tr>
      <th>60</th>
      <td>speech recognition</td>
      <td>4.384831</td>
    </tr>
    <tr>
      <th>61</th>
      <td>regularization term</td>
      <td>4.382222</td>
    </tr>
    <tr>
      <th>62</th>
      <td>make errors</td>
      <td>4.371736</td>
    </tr>
    <tr>
      <th>63</th>
      <td>training sets</td>
      <td>4.357458</td>
    </tr>
    <tr>
      <th>64</th>
      <td>recent work</td>
      <td>4.356250</td>
    </tr>
    <tr>
      <th>65</th>
      <td>prior work</td>
      <td>4.355556</td>
    </tr>
    <tr>
      <th>66</th>
      <td>processing step</td>
      <td>4.344828</td>
    </tr>
    <tr>
      <th>67</th>
      <td>loss function</td>
      <td>4.336596</td>
    </tr>
    <tr>
      <th>68</th>
      <td>art results</td>
      <td>4.336089</td>
    </tr>
    <tr>
      <th>69</th>
      <td>high confidence</td>
      <td>4.335000</td>
    </tr>
    <tr>
      <th>70</th>
      <td>dnn models</td>
      <td>4.334036</td>
    </tr>
    <tr>
      <th>71</th>
      <td>data samples</td>
      <td>4.319925</td>
    </tr>
    <tr>
      <th>72</th>
      <td>art models</td>
      <td>4.311419</td>
    </tr>
    <tr>
      <th>73</th>
      <td>test time</td>
      <td>4.298137</td>
    </tr>
    <tr>
      <th>74</th>
      <td>learning systems</td>
      <td>4.296858</td>
    </tr>
    <tr>
      <th>75</th>
      <td>data augmentation</td>
      <td>4.284211</td>
    </tr>
    <tr>
      <th>76</th>
      <td>real world</td>
      <td>4.276316</td>
    </tr>
    <tr>
      <th>77</th>
      <td>computer vision</td>
      <td>4.273050</td>
    </tr>
    <tr>
      <th>78</th>
      <td>lower bound</td>
      <td>4.272727</td>
    </tr>
    <tr>
      <th>79</th>
      <td>box attack</td>
      <td>4.255708</td>
    </tr>
    <tr>
      <th>80</th>
      <td>recent studies</td>
      <td>4.250590</td>
    </tr>
    <tr>
      <th>81</th>
      <td>physical world</td>
      <td>4.245951</td>
    </tr>
    <tr>
      <th>82</th>
      <td>adversarial examples</td>
      <td>4.240057</td>
    </tr>
    <tr>
      <th>83</th>
      <td>art methods</td>
      <td>4.237043</td>
    </tr>
    <tr>
      <th>84</th>
      <td>upper bound</td>
      <td>4.235294</td>
    </tr>
    <tr>
      <th>85</th>
      <td>inference time</td>
      <td>4.234773</td>
    </tr>
    <tr>
      <th>86</th>
      <td>federated learning</td>
      <td>4.233396</td>
    </tr>
    <tr>
      <th>87</th>
      <td>learning process</td>
      <td>4.233396</td>
    </tr>
    <tr>
      <th>88</th>
      <td>object detection</td>
      <td>4.230296</td>
    </tr>
    <tr>
      <th>89</th>
      <td>box attacks</td>
      <td>4.218117</td>
    </tr>
    <tr>
      <th>90</th>
      <td>feature space</td>
      <td>4.217384</td>
    </tr>
    <tr>
      <th>91</th>
      <td>generative model</td>
      <td>4.205007</td>
    </tr>
    <tr>
      <th>92</th>
      <td>current methods</td>
      <td>4.204044</td>
    </tr>
    <tr>
      <th>93</th>
      <td>adversarial samples</td>
      <td>4.188815</td>
    </tr>
    <tr>
      <th>94</th>
      <td>training data</td>
      <td>4.187123</td>
    </tr>
    <tr>
      <th>95</th>
      <td>input data</td>
      <td>4.183774</td>
    </tr>
    <tr>
      <th>96</th>
      <td>learned models</td>
      <td>4.179490</td>
    </tr>
    <tr>
      <th>97</th>
      <td>box model</td>
      <td>4.179487</td>
    </tr>
    <tr>
      <th>98</th>
      <td>data manifold</td>
      <td>4.178947</td>
    </tr>
    <tr>
      <th>99</th>
      <td>human vision</td>
      <td>4.176190</td>
    </tr>
    <tr>
      <th>100</th>
      <td>box settings</td>
      <td>4.175214</td>
    </tr>
    <tr>
      <th>101</th>
      <td>art attacks</td>
      <td>4.172307</td>
    </tr>
    <tr>
      <th>102</th>
      <td>latent space</td>
      <td>4.169799</td>
    </tr>
    <tr>
      <th>103</th>
      <td>visual quality</td>
      <td>4.163328</td>
    </tr>
    <tr>
      <th>104</th>
      <td>poisoning attack</td>
      <td>4.160356</td>
    </tr>
    <tr>
      <th>105</th>
      <td>training set</td>
      <td>4.160055</td>
    </tr>
    <tr>
      <th>106</th>
      <td>dnn model</td>
      <td>4.156294</td>
    </tr>
    <tr>
      <th>107</th>
      <td>2d images</td>
      <td>4.144985</td>
    </tr>
    <tr>
      <th>108</th>
      <td>adversarial image</td>
      <td>4.139147</td>
    </tr>
    <tr>
      <th>109</th>
      <td>previous work</td>
      <td>4.137500</td>
    </tr>
    <tr>
      <th>110</th>
      <td>empirically show</td>
      <td>4.135398</td>
    </tr>
    <tr>
      <th>111</th>
      <td>show empirically</td>
      <td>4.135398</td>
    </tr>
    <tr>
      <th>112</th>
      <td>data distribution</td>
      <td>4.135274</td>
    </tr>
    <tr>
      <th>113</th>
      <td>malicious perturbations</td>
      <td>4.129483</td>
    </tr>
    <tr>
      <th>114</th>
      <td>semantic segmentation</td>
      <td>4.125508</td>
    </tr>
    <tr>
      <th>115</th>
      <td>experiments show</td>
      <td>4.124673</td>
    </tr>
    <tr>
      <th>116</th>
      <td>poisoning attacks</td>
      <td>4.122764</td>
    </tr>
    <tr>
      <th>117</th>
      <td>true label</td>
      <td>4.110714</td>
    </tr>
    <tr>
      <th>118</th>
      <td>defense mechanism</td>
      <td>4.108173</td>
    </tr>
    <tr>
      <th>119</th>
      <td>recent works</td>
      <td>4.107470</td>
    </tr>
    <tr>
      <th>120</th>
      <td>original image</td>
      <td>4.106528</td>
    </tr>
    <tr>
      <th>121</th>
      <td>data points</td>
      <td>4.105639</td>
    </tr>
    <tr>
      <th>122</th>
      <td>adversarial attack</td>
      <td>4.094707</td>
    </tr>
    <tr>
      <th>123</th>
      <td>existing methods</td>
      <td>4.093750</td>
    </tr>
    <tr>
      <th>124</th>
      <td>box setting</td>
      <td>4.091880</td>
    </tr>
    <tr>
      <th>125</th>
      <td>mutual information</td>
      <td>4.087755</td>
    </tr>
    <tr>
      <th>126</th>
      <td>high accuracy</td>
      <td>4.079545</td>
    </tr>
    <tr>
      <th>127</th>
      <td>adversarial noise</td>
      <td>4.077832</td>
    </tr>
    <tr>
      <th>128</th>
      <td>recognition systems</td>
      <td>4.073293</td>
    </tr>
    <tr>
      <th>129</th>
      <td>art performance</td>
      <td>4.068293</td>
    </tr>
    <tr>
      <th>130</th>
      <td>annotated images</td>
      <td>4.067207</td>
    </tr>
    <tr>
      <th>131</th>
      <td>theoretical analysis</td>
      <td>4.063871</td>
    </tr>
    <tr>
      <th>132</th>
      <td>defensive distillation</td>
      <td>4.061111</td>
    </tr>
    <tr>
      <th>133</th>
      <td>threat models</td>
      <td>4.059000</td>
    </tr>
    <tr>
      <th>134</th>
      <td>physical attacks</td>
      <td>4.057860</td>
    </tr>
    <tr>
      <th>135</th>
      <td>adversarial attacks</td>
      <td>4.057115</td>
    </tr>
    <tr>
      <th>136</th>
      <td>box scenarios</td>
      <td>4.056960</td>
    </tr>
    <tr>
      <th>137</th>
      <td>adversarial training</td>
      <td>4.056013</td>
    </tr>
    <tr>
      <th>138</th>
      <td>autonomous vehicles</td>
      <td>4.055556</td>
    </tr>
    <tr>
      <th>139</th>
      <td>target models</td>
      <td>4.052386</td>
    </tr>
    <tr>
      <th>140</th>
      <td>recent research</td>
      <td>4.043574</td>
    </tr>
    <tr>
      <th>141</th>
      <td>attack algorithms</td>
      <td>4.041606</td>
    </tr>
    <tr>
      <th>142</th>
      <td>networks trained</td>
      <td>4.041150</td>
    </tr>
    <tr>
      <th>143</th>
      <td>multiple attacks</td>
      <td>4.034449</td>
    </tr>
    <tr>
      <th>144</th>
      <td>defense mechanisms</td>
      <td>4.031250</td>
    </tr>
    <tr>
      <th>145</th>
      <td>adversarial perturbations</td>
      <td>4.025441</td>
    </tr>
    <tr>
      <th>146</th>
      <td>iterative attacks</td>
      <td>4.021661</td>
    </tr>
    <tr>
      <th>147</th>
      <td>attack strategies</td>
      <td>4.020553</td>
    </tr>
    <tr>
      <th>148</th>
      <td>object detectors</td>
      <td>4.016885</td>
    </tr>
    <tr>
      <th>149</th>
      <td>adversarial settings</td>
      <td>4.014212</td>
    </tr>
    <tr>
      <th>150</th>
      <td>objective function</td>
      <td>4.013488</td>
    </tr>
    <tr>
      <th>151</th>
      <td>human eye</td>
      <td>4.009524</td>
    </tr>
    <tr>
      <th>152</th>
      <td>human eyes</td>
      <td>4.009524</td>
    </tr>
    <tr>
      <th>153</th>
      <td>perturbed images</td>
      <td>4.004076</td>
    </tr>
    <tr>
      <th>154</th>
      <td>learned model</td>
      <td>4.001748</td>
    </tr>
    <tr>
      <th>155</th>
      <td>extensive experiments</td>
      <td>4.000934</td>
    </tr>
    <tr>
      <th>156</th>
      <td>defense methods</td>
      <td>4.000000</td>
    </tr>
    <tr>
      <th>157</th>
      <td>multiscale processing</td>
      <td>4.000000</td>
    </tr>
    <tr>
      <th>158</th>
      <td>adversarial images</td>
      <td>3.998086</td>
    </tr>
    <tr>
      <th>159</th>
      <td>image space</td>
      <td>3.997951</td>
    </tr>
    <tr>
      <th>160</th>
      <td>random noise</td>
      <td>3.992913</td>
    </tr>
    <tr>
      <th>161</th>
      <td>universal perturbations</td>
      <td>3.992340</td>
    </tr>
    <tr>
      <th>162</th>
      <td>adversarial perturbation</td>
      <td>3.987746</td>
    </tr>
    <tr>
      <th>163</th>
      <td>input examples</td>
      <td>3.986520</td>
    </tr>
    <tr>
      <th>164</th>
      <td>critical systems</td>
      <td>3.980128</td>
    </tr>
    <tr>
      <th>165</th>
      <td>benign examples</td>
      <td>3.975845</td>
    </tr>
    <tr>
      <th>166</th>
      <td>image classification</td>
      <td>3.974373</td>
    </tr>
    <tr>
      <th>167</th>
      <td>large margin</td>
      <td>3.972097</td>
    </tr>
    <tr>
      <th>168</th>
      <td>based models</td>
      <td>3.966484</td>
    </tr>
    <tr>
      <th>169</th>
      <td>original images</td>
      <td>3.965467</td>
    </tr>
    <tr>
      <th>170</th>
      <td>classification tasks</td>
      <td>3.963117</td>
    </tr>
    <tr>
      <th>171</th>
      <td>perceptual similarity</td>
      <td>3.961538</td>
    </tr>
    <tr>
      <th>172</th>
      <td>final layer</td>
      <td>3.961404</td>
    </tr>
    <tr>
      <th>173</th>
      <td>point clouds</td>
      <td>3.947368</td>
    </tr>
    <tr>
      <th>174</th>
      <td>adversarially trained</td>
      <td>3.942425</td>
    </tr>
    <tr>
      <th>175</th>
      <td>successfully attack</td>
      <td>3.941606</td>
    </tr>
    <tr>
      <th>176</th>
      <td>random perturbations</td>
      <td>3.940522</td>
    </tr>
    <tr>
      <th>177</th>
      <td>hidden layers</td>
      <td>3.928118</td>
    </tr>
    <tr>
      <th>178</th>
      <td>target label</td>
      <td>3.919974</td>
    </tr>
    <tr>
      <th>179</th>
      <td>classification problems</td>
      <td>3.913327</td>
    </tr>
    <tr>
      <th>180</th>
      <td>art defenses</td>
      <td>3.913152</td>
    </tr>
    <tr>
      <th>181</th>
      <td>input space</td>
      <td>3.911468</td>
    </tr>
    <tr>
      <th>182</th>
      <td>attack methods</td>
      <td>3.910356</td>
    </tr>
    <tr>
      <th>183</th>
      <td>test accuracy</td>
      <td>3.907444</td>
    </tr>
    <tr>
      <th>184</th>
      <td>previous methods</td>
      <td>3.906250</td>
    </tr>
    <tr>
      <th>185</th>
      <td>evasion attacks</td>
      <td>3.904014</td>
    </tr>
    <tr>
      <th>186</th>
      <td>backdoor attacks</td>
      <td>3.904014</td>
    </tr>
    <tr>
      <th>187</th>
      <td>defense strategy</td>
      <td>3.902218</td>
    </tr>
    <tr>
      <th>188</th>
      <td>clean samples</td>
      <td>3.899351</td>
    </tr>
    <tr>
      <th>189</th>
      <td>activation functions</td>
      <td>3.893478</td>
    </tr>
    <tr>
      <th>190</th>
      <td>previous works</td>
      <td>3.888720</td>
    </tr>
    <tr>
      <th>191</th>
      <td>detection method</td>
      <td>3.887422</td>
    </tr>
    <tr>
      <th>192</th>
      <td>input image</td>
      <td>3.885610</td>
    </tr>
    <tr>
      <th>193</th>
      <td>threat model</td>
      <td>3.881258</td>
    </tr>
    <tr>
      <th>194</th>
      <td>target model</td>
      <td>3.874644</td>
    </tr>
    <tr>
      <th>195</th>
      <td>adversarial subspaces</td>
      <td>3.853101</td>
    </tr>
    <tr>
      <th>196</th>
      <td>network architectures</td>
      <td>3.852848</td>
    </tr>
    <tr>
      <th>197</th>
      <td>video frames</td>
      <td>3.848077</td>
    </tr>
    <tr>
      <th>198</th>
      <td>training dataset</td>
      <td>3.844089</td>
    </tr>
    <tr>
      <th>199</th>
      <td>image classifiers</td>
      <td>3.840885</td>
    </tr>
    <tr>
      <th>200</th>
      <td>adversarial inputs</td>
      <td>3.834919</td>
    </tr>
    <tr>
      <th>201</th>
      <td>social media</td>
      <td>3.833333</td>
    </tr>
    <tr>
      <th>202</th>
      <td>trained models</td>
      <td>3.827657</td>
    </tr>
    <tr>
      <th>203</th>
      <td>models trained</td>
      <td>3.827657</td>
    </tr>
    <tr>
      <th>204</th>
      <td>based attacks</td>
      <td>3.827372</td>
    </tr>
    <tr>
      <th>205</th>
      <td>underlying model</td>
      <td>3.823718</td>
    </tr>
    <tr>
      <th>206</th>
      <td>classified incorrectly</td>
      <td>3.818182</td>
    </tr>
    <tr>
      <th>207</th>
      <td>natural images</td>
      <td>3.816816</td>
    </tr>
    <tr>
      <th>208</th>
      <td>input features</td>
      <td>3.810454</td>
    </tr>
    <tr>
      <th>209</th>
      <td>small perturbations</td>
      <td>3.809840</td>
    </tr>
    <tr>
      <th>210</th>
      <td>critical applications</td>
      <td>3.809109</td>
    </tr>
    <tr>
      <th>211</th>
      <td>recent years</td>
      <td>3.796250</td>
    </tr>
    <tr>
      <th>212</th>
      <td>open problem</td>
      <td>3.793527</td>
    </tr>
    <tr>
      <th>213</th>
      <td>classification performance</td>
      <td>3.788327</td>
    </tr>
    <tr>
      <th>214</th>
      <td>training process</td>
      <td>3.777913</td>
    </tr>
    <tr>
      <th>215</th>
      <td>small perturbation</td>
      <td>3.772146</td>
    </tr>
    <tr>
      <th>216</th>
      <td>based system</td>
      <td>3.768428</td>
    </tr>
    <tr>
      <th>217</th>
      <td>decision boundary</td>
      <td>3.765738</td>
    </tr>
    <tr>
      <th>218</th>
      <td>wide range</td>
      <td>3.763134</td>
    </tr>
    <tr>
      <th>219</th>
      <td>trained network</td>
      <td>3.762378</td>
    </tr>
    <tr>
      <th>220</th>
      <td>adding small</td>
      <td>3.761029</td>
    </tr>
    <tr>
      <th>221</th>
      <td>training distribution</td>
      <td>3.753976</td>
    </tr>
    <tr>
      <th>222</th>
      <td>results suggest</td>
      <td>3.746368</td>
    </tr>
    <tr>
      <th>223</th>
      <td>input images</td>
      <td>3.744548</td>
    </tr>
    <tr>
      <th>224</th>
      <td>obfuscated gradients</td>
      <td>3.741935</td>
    </tr>
    <tr>
      <th>225</th>
      <td>target class</td>
      <td>3.724856</td>
    </tr>
    <tr>
      <th>226</th>
      <td>decision boundaries</td>
      <td>3.724561</td>
    </tr>
    <tr>
      <th>227</th>
      <td>clean images</td>
      <td>3.708621</td>
    </tr>
    <tr>
      <th>228</th>
      <td>differential privacy</td>
      <td>3.704545</td>
    </tr>
    <tr>
      <th>229</th>
      <td>target person</td>
      <td>3.701567</td>
    </tr>
    <tr>
      <th>230</th>
      <td>classification accuracy</td>
      <td>3.692872</td>
    </tr>
    <tr>
      <th>231</th>
      <td>security concerns</td>
      <td>3.685714</td>
    </tr>
    <tr>
      <th>232</th>
      <td>agnostic perturbations</td>
      <td>3.681864</td>
    </tr>
    <tr>
      <th>233</th>
      <td>trained model</td>
      <td>3.649915</td>
    </tr>
    <tr>
      <th>234</th>
      <td>large datasets</td>
      <td>3.637286</td>
    </tr>
    <tr>
      <th>235</th>
      <td>adversarial robustness</td>
      <td>3.637177</td>
    </tr>
    <tr>
      <th>236</th>
      <td>prior knowledge</td>
      <td>3.626144</td>
    </tr>
    <tr>
      <th>237</th>
      <td>human perception</td>
      <td>3.620635</td>
    </tr>
    <tr>
      <th>238</th>
      <td>benchmark datasets</td>
      <td>3.607949</td>
    </tr>
    <tr>
      <th>239</th>
      <td>significantly improve</td>
      <td>3.564808</td>
    </tr>
    <tr>
      <th>240</th>
      <td>existing black</td>
      <td>3.556655</td>
    </tr>
    <tr>
      <th>241</th>
      <td>imperceptible perturbations</td>
      <td>3.549264</td>
    </tr>
    <tr>
      <th>242</th>
      <td>image classifier</td>
      <td>3.524508</td>
    </tr>
    <tr>
      <th>243</th>
      <td>current state</td>
      <td>3.523851</td>
    </tr>
    <tr>
      <th>244</th>
      <td>proposed algorithm</td>
      <td>3.521299</td>
    </tr>
    <tr>
      <th>245</th>
      <td>proposed method</td>
      <td>3.520176</td>
    </tr>
    <tr>
      <th>246</th>
      <td>small subset</td>
      <td>3.508929</td>
    </tr>
    <tr>
      <th>247</th>
      <td>facial attributes</td>
      <td>3.500000</td>
    </tr>
    <tr>
      <th>248</th>
      <td>robust features</td>
      <td>3.495925</td>
    </tr>
    <tr>
      <th>249</th>
      <td>results demonstrate</td>
      <td>3.486236</td>
    </tr>
    <tr>
      <th>250</th>
      <td>highly susceptible</td>
      <td>3.464286</td>
    </tr>
    <tr>
      <th>251</th>
      <td>knowledge distillation</td>
      <td>3.420588</td>
    </tr>
    <tr>
      <th>252</th>
      <td>small number</td>
      <td>3.405585</td>
    </tr>
    <tr>
      <th>253</th>
      <td>wide variety</td>
      <td>3.396825</td>
    </tr>
    <tr>
      <th>254</th>
      <td>imagenet datasets</td>
      <td>3.366487</td>
    </tr>
    <tr>
      <th>255</th>
      <td>optimization problem</td>
      <td>3.361471</td>
    </tr>
    <tr>
      <th>256</th>
      <td>model robustness</td>
      <td>3.349461</td>
    </tr>
    <tr>
      <th>257</th>
      <td>proposed approach</td>
      <td>3.343886</td>
    </tr>
    <tr>
      <th>258</th>
      <td>paper proposes</td>
      <td>3.309492</td>
    </tr>
    <tr>
      <th>259</th>
      <td>effective method</td>
      <td>3.273315</td>
    </tr>
    <tr>
      <th>260</th>
      <td>mnist dataset</td>
      <td>3.251176</td>
    </tr>
    <tr>
      <th>261</th>
      <td>variational autoencoder</td>
      <td>3.250000</td>
    </tr>
    <tr>
      <th>262</th>
      <td>model parameters</td>
      <td>3.237934</td>
    </tr>
    <tr>
      <th>263</th>
      <td>highly vulnerable</td>
      <td>3.200188</td>
    </tr>
    <tr>
      <th>264</th>
      <td>achieved state</td>
      <td>3.185993</td>
    </tr>
    <tr>
      <th>265</th>
      <td>experiments conducted</td>
      <td>3.174603</td>
    </tr>
    <tr>
      <th>266</th>
      <td>easily fooled</td>
      <td>3.172500</td>
    </tr>
    <tr>
      <th>267</th>
      <td>experiments demonstrate</td>
      <td>3.164471</td>
    </tr>
    <tr>
      <th>268</th>
      <td>paper presents</td>
      <td>3.131714</td>
    </tr>
    <tr>
      <th>269</th>
      <td>cifar10 datasets</td>
      <td>3.106098</td>
    </tr>
    <tr>
      <th>270</th>
      <td>achieve state</td>
      <td>3.070375</td>
    </tr>
    <tr>
      <th>271</th>
      <td>improve robustness</td>
      <td>2.926934</td>
    </tr>
    <tr>
      <th>272</th>
      <td>paper focuses</td>
      <td>2.823381</td>
    </tr>
    <tr>
      <th>273</th>
      <td>widely applied</td>
      <td>2.683198</td>
    </tr>
    <tr>
      <th>274</th>
      <td>10 datasets</td>
      <td>1.756098</td>
    </tr>
  </tbody>
</table>