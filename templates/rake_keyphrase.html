<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Key Phrase: RAKE</th>
      <th>Score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>deep neural networks</td>
      <td>7.476131</td>
    </tr>
    <tr>
      <th>1</th>
      <td>convolutional neural networks</td>
      <td>7.456304</td>
    </tr>
    <tr>
      <th>2</th>
      <td>deep neural network</td>
      <td>7.229615</td>
    </tr>
    <tr>
      <th>3</th>
      <td>convolutional neural network</td>
      <td>7.209788</td>
    </tr>
    <tr>
      <th>4</th>
      <td>injecting adversarial examples</td>
      <td>7.136081</td>
    </tr>
    <tr>
      <th>5</th>
      <td>deep learning algorithms</td>
      <td>7.095566</td>
    </tr>
    <tr>
      <th>6</th>
      <td>deep learning models</td>
      <td>7.025462</td>
    </tr>
    <tr>
      <th>7</th>
      <td>deep learning systems</td>
      <td>6.966888</td>
    </tr>
    <tr>
      <th>8</th>
      <td>adversarial machine learning</td>
      <td>6.911027</td>
    </tr>
    <tr>
      <th>9</th>
      <td>experimental results show</td>
      <td>6.854601</td>
    </tr>
    <tr>
      <th>10</th>
      <td>machine learning algorithms</td>
      <td>6.848812</td>
    </tr>
    <tr>
      <th>11</th>
      <td>machine learning models</td>
      <td>6.778708</td>
    </tr>
    <tr>
      <th>12</th>
      <td>generative adversarial networks</td>
      <td>6.765760</td>
    </tr>
    <tr>
      <th>13</th>
      <td>machine learning tasks</td>
      <td>6.746450</td>
    </tr>
    <tr>
      <th>14</th>
      <td>machine learning systems</td>
      <td>6.720134</td>
    </tr>
    <tr>
      <th>15</th>
      <td>attack success rate</td>
      <td>6.678534</td>
    </tr>
    <tr>
      <th>16</th>
      <td>machine learning classifiers</td>
      <td>6.625644</td>
    </tr>
    <tr>
      <th>17</th>
      <td>recent studies show</td>
      <td>6.614621</td>
    </tr>
    <tr>
      <th>18</th>
      <td>machine learning model</td>
      <td>6.609588</td>
    </tr>
    <tr>
      <th>19</th>
      <td>generative adversarial network</td>
      <td>6.519244</td>
    </tr>
    <tr>
      <th>20</th>
      <td>box adversarial attacks</td>
      <td>6.429201</td>
    </tr>
    <tr>
      <th>21</th>
      <td>box threat models</td>
      <td>6.403453</td>
    </tr>
    <tr>
      <th>22</th>
      <td>generating adversarial examples</td>
      <td>6.399012</td>
    </tr>
    <tr>
      <th>23</th>
      <td>adversarial examples generated</td>
      <td>6.398067</td>
    </tr>
    <tr>
      <th>24</th>
      <td>computer vision tasks</td>
      <td>6.289231</td>
    </tr>
    <tr>
      <th>25</th>
      <td>box attack settings</td>
      <td>6.185356</td>
    </tr>
    <tr>
      <th>26</th>
      <td>detecting adversarial examples</td>
      <td>6.152973</td>
    </tr>
    <tr>
      <th>27</th>
      <td>generate adversarial examples</td>
      <td>6.132876</td>
    </tr>
    <tr>
      <th>28</th>
      <td>human visual system</td>
      <td>6.126068</td>
    </tr>
    <tr>
      <th>29</th>
      <td>conduct extensive experiments</td>
      <td>6.085855</td>
    </tr>
    <tr>
      <th>30</th>
      <td>image classification tasks</td>
      <td>5.998416</td>
    </tr>
    <tr>
      <th>31</th>
      <td>small adversarial perturbations</td>
      <td>5.990657</td>
    </tr>
    <tr>
      <th>32</th>
      <td>transferable adversarial examples</td>
      <td>5.948581</td>
    </tr>
    <tr>
      <th>33</th>
      <td>black box attacks</td>
      <td>5.676745</td>
    </tr>
    <tr>
      <th>34</th>
      <td>deep neural</td>
      <td>5.221615</td>
    </tr>
    <tr>
      <th>35</th>
      <td>convolutional neural</td>
      <td>5.201788</td>
    </tr>
    <tr>
      <th>36</th>
      <td>deep learning</td>
      <td>4.993204</td>
    </tr>
    <tr>
      <th>37</th>
      <td>deep networks</td>
      <td>4.897719</td>
    </tr>
    <tr>
      <th>38</th>
      <td>reinforcement learning</td>
      <td>4.883333</td>
    </tr>
    <tr>
      <th>39</th>
      <td>convolutional networks</td>
      <td>4.877892</td>
    </tr>
    <tr>
      <th>40</th>
      <td>neural networks</td>
      <td>4.832927</td>
    </tr>
    <tr>
      <th>41</th>
      <td>machine learning</td>
      <td>4.746450</td>
    </tr>
    <tr>
      <th>42</th>
      <td>success rate</td>
      <td>4.715956</td>
    </tr>
    <tr>
      <th>43</th>
      <td>deep models</td>
      <td>4.675462</td>
    </tr>
    <tr>
      <th>44</th>
      <td>stop sign</td>
      <td>4.660714</td>
    </tr>
    <tr>
      <th>45</th>
      <td>face recognition</td>
      <td>4.655601</td>
    </tr>
    <tr>
      <th>46</th>
      <td>deep network</td>
      <td>4.651204</td>
    </tr>
    <tr>
      <th>47</th>
      <td>jpeg compression</td>
      <td>4.646724</td>
    </tr>
    <tr>
      <th>48</th>
      <td>neural network</td>
      <td>4.586411</td>
    </tr>
    <tr>
      <th>49</th>
      <td>saak transform</td>
      <td>4.544444</td>
    </tr>
    <tr>
      <th>50</th>
      <td>deep architectures</td>
      <td>4.502579</td>
    </tr>
    <tr>
      <th>51</th>
      <td>data poisoning</td>
      <td>4.502332</td>
    </tr>
    <tr>
      <th>52</th>
      <td>supervised learning</td>
      <td>4.492857</td>
    </tr>
    <tr>
      <th>53</th>
      <td>experimental results</td>
      <td>4.490965</td>
    </tr>
    <tr>
      <th>54</th>
      <td>test data</td>
      <td>4.470249</td>
    </tr>
    <tr>
      <th>55</th>
      <td>results show</td>
      <td>4.468636</td>
    </tr>
    <tr>
      <th>56</th>
      <td>generative modeling</td>
      <td>4.464314</td>
    </tr>
    <tr>
      <th>57</th>
      <td>learning algorithms</td>
      <td>4.452362</td>
    </tr>
    <tr>
      <th>58</th>
      <td>computational cost</td>
      <td>4.447293</td>
    </tr>
    <tr>
      <th>59</th>
      <td>high confidence</td>
      <td>4.433667</td>
    </tr>
    <tr>
      <th>60</th>
      <td>adversarial networks</td>
      <td>4.419093</td>
    </tr>
    <tr>
      <th>61</th>
      <td>regularization term</td>
      <td>4.404040</td>
    </tr>
    <tr>
      <th>62</th>
      <td>speech recognition</td>
      <td>4.395694</td>
    </tr>
    <tr>
      <th>63</th>
      <td>driving cars</td>
      <td>4.393939</td>
    </tr>
    <tr>
      <th>64</th>
      <td>autonomous driving</td>
      <td>4.389435</td>
    </tr>
    <tr>
      <th>65</th>
      <td>carefully crafted</td>
      <td>4.385522</td>
    </tr>
    <tr>
      <th>66</th>
      <td>prior work</td>
      <td>4.382704</td>
    </tr>
    <tr>
      <th>67</th>
      <td>learning models</td>
      <td>4.382258</td>
    </tr>
    <tr>
      <th>68</th>
      <td>latent variables</td>
      <td>4.381818</td>
    </tr>
    <tr>
      <th>69</th>
      <td>art results</td>
      <td>4.377727</td>
    </tr>
    <tr>
      <th>70</th>
      <td>box scenario</td>
      <td>4.377463</td>
    </tr>
    <tr>
      <th>71</th>
      <td>recent work</td>
      <td>4.372057</td>
    </tr>
    <tr>
      <th>72</th>
      <td>processing step</td>
      <td>4.361672</td>
    </tr>
    <tr>
      <th>73</th>
      <td>current dnns</td>
      <td>4.361598</td>
    </tr>
    <tr>
      <th>74</th>
      <td>data augmentation</td>
      <td>4.360505</td>
    </tr>
    <tr>
      <th>75</th>
      <td>causal graph</td>
      <td>4.358289</td>
    </tr>
    <tr>
      <th>76</th>
      <td>3d objects</td>
      <td>4.354926</td>
    </tr>
    <tr>
      <th>77</th>
      <td>loss function</td>
      <td>4.338983</td>
    </tr>
    <tr>
      <th>78</th>
      <td>empirical evaluations</td>
      <td>4.333333</td>
    </tr>
    <tr>
      <th>79</th>
      <td>data samples</td>
      <td>4.332965</td>
    </tr>
    <tr>
      <th>80</th>
      <td>dnn models</td>
      <td>4.325362</td>
    </tr>
    <tr>
      <th>81</th>
      <td>learning systems</td>
      <td>4.323684</td>
    </tr>
    <tr>
      <th>82</th>
      <td>test time</td>
      <td>4.321282</td>
    </tr>
    <tr>
      <th>83</th>
      <td>training sets</td>
      <td>4.320413</td>
    </tr>
    <tr>
      <th>84</th>
      <td>sum game</td>
      <td>4.315789</td>
    </tr>
    <tr>
      <th>85</th>
      <td>step attacks</td>
      <td>4.314442</td>
    </tr>
    <tr>
      <th>86</th>
      <td>art models</td>
      <td>4.304985</td>
    </tr>
    <tr>
      <th>87</th>
      <td>box attack</td>
      <td>4.303003</td>
    </tr>
    <tr>
      <th>88</th>
      <td>make errors</td>
      <td>4.299020</td>
    </tr>
    <tr>
      <th>89</th>
      <td>computer vision</td>
      <td>4.289231</td>
    </tr>
    <tr>
      <th>90</th>
      <td>spatial transformation</td>
      <td>4.280952</td>
    </tr>
    <tr>
      <th>91</th>
      <td>lower bound</td>
      <td>4.280000</td>
    </tr>
    <tr>
      <th>92</th>
      <td>impressive performance</td>
      <td>4.272947</td>
    </tr>
    <tr>
      <th>93</th>
      <td>object detection</td>
      <td>4.267267</td>
    </tr>
    <tr>
      <th>94</th>
      <td>box attacks</td>
      <td>4.264624</td>
    </tr>
    <tr>
      <th>95</th>
      <td>adversarial examples</td>
      <td>4.261081</td>
    </tr>
    <tr>
      <th>96</th>
      <td>latent space</td>
      <td>4.260870</td>
    </tr>
    <tr>
      <th>97</th>
      <td>art methods</td>
      <td>4.259394</td>
    </tr>
    <tr>
      <th>98</th>
      <td>recent studies</td>
      <td>4.250985</td>
    </tr>
    <tr>
      <th>99</th>
      <td>real world</td>
      <td>4.240741</td>
    </tr>
    <tr>
      <th>100</th>
      <td>upper bound</td>
      <td>4.235294</td>
    </tr>
    <tr>
      <th>101</th>
      <td>physical world</td>
      <td>4.234788</td>
    </tr>
    <tr>
      <th>102</th>
      <td>federated learning</td>
      <td>4.225000</td>
    </tr>
    <tr>
      <th>103</th>
      <td>box settings</td>
      <td>4.222778</td>
    </tr>
    <tr>
      <th>104</th>
      <td>feature space</td>
      <td>4.219406</td>
    </tr>
    <tr>
      <th>105</th>
      <td>training data</td>
      <td>4.219380</td>
    </tr>
    <tr>
      <th>106</th>
      <td>data manifold</td>
      <td>4.218365</td>
    </tr>
    <tr>
      <th>107</th>
      <td>adversarial samples</td>
      <td>4.213960</td>
    </tr>
    <tr>
      <th>108</th>
      <td>learning process</td>
      <td>4.213636</td>
    </tr>
    <tr>
      <th>109</th>
      <td>human vision</td>
      <td>4.211966</td>
    </tr>
    <tr>
      <th>110</th>
      <td>generative model</td>
      <td>4.209805</td>
    </tr>
    <tr>
      <th>111</th>
      <td>theoretical analysis</td>
      <td>4.207437</td>
    </tr>
    <tr>
      <th>112</th>
      <td>box model</td>
      <td>4.203564</td>
    </tr>
    <tr>
      <th>113</th>
      <td>art attacks</td>
      <td>4.196926</td>
    </tr>
    <tr>
      <th>114</th>
      <td>inference time</td>
      <td>4.193439</td>
    </tr>
    <tr>
      <th>115</th>
      <td>current methods</td>
      <td>4.190370</td>
    </tr>
    <tr>
      <th>116</th>
      <td>poisoning attack</td>
      <td>4.181328</td>
    </tr>
    <tr>
      <th>117</th>
      <td>input data</td>
      <td>4.176302</td>
    </tr>
    <tr>
      <th>118</th>
      <td>box setting</td>
      <td>4.173759</td>
    </tr>
    <tr>
      <th>119</th>
      <td>previous work</td>
      <td>4.173703</td>
    </tr>
    <tr>
      <th>120</th>
      <td>malicious perturbations</td>
      <td>4.173273</td>
    </tr>
    <tr>
      <th>121</th>
      <td>adversarial image</td>
      <td>4.166657</td>
    </tr>
    <tr>
      <th>122</th>
      <td>training set</td>
      <td>4.166567</td>
    </tr>
    <tr>
      <th>123</th>
      <td>adversarial domain</td>
      <td>4.164578</td>
    </tr>
    <tr>
      <th>124</th>
      <td>data points</td>
      <td>4.162370</td>
    </tr>
    <tr>
      <th>125</th>
      <td>defense mechanism</td>
      <td>4.161964</td>
    </tr>
    <tr>
      <th>126</th>
      <td>empirically show</td>
      <td>4.159091</td>
    </tr>
    <tr>
      <th>127</th>
      <td>show empirically</td>
      <td>4.159091</td>
    </tr>
    <tr>
      <th>128</th>
      <td>dnn model</td>
      <td>4.156242</td>
    </tr>
    <tr>
      <th>129</th>
      <td>2d images</td>
      <td>4.149003</td>
    </tr>
    <tr>
      <th>130</th>
      <td>poisoning attacks</td>
      <td>4.142948</td>
    </tr>
    <tr>
      <th>131</th>
      <td>recognition systems</td>
      <td>4.142105</td>
    </tr>
    <tr>
      <th>132</th>
      <td>existing methods</td>
      <td>4.141306</td>
    </tr>
    <tr>
      <th>133</th>
      <td>experiments show</td>
      <td>4.139147</td>
    </tr>
    <tr>
      <th>134</th>
      <td>adversarial attack</td>
      <td>4.127156</td>
    </tr>
    <tr>
      <th>135</th>
      <td>data distribution</td>
      <td>4.126102</td>
    </tr>
    <tr>
      <th>136</th>
      <td>box scenarios</td>
      <td>4.124209</td>
    </tr>
    <tr>
      <th>137</th>
      <td>original image</td>
      <td>4.122958</td>
    </tr>
    <tr>
      <th>138</th>
      <td>attack strategies</td>
      <td>4.118134</td>
    </tr>
    <tr>
      <th>139</th>
      <td>adversarial noise</td>
      <td>4.114578</td>
    </tr>
    <tr>
      <th>140</th>
      <td>adversarial training</td>
      <td>4.100375</td>
    </tr>
    <tr>
      <th>141</th>
      <td>high accuracy</td>
      <td>4.098523</td>
    </tr>
    <tr>
      <th>142</th>
      <td>true label</td>
      <td>4.097222</td>
    </tr>
    <tr>
      <th>143</th>
      <td>learned models</td>
      <td>4.092258</td>
    </tr>
    <tr>
      <th>144</th>
      <td>visual quality</td>
      <td>4.092105</td>
    </tr>
    <tr>
      <th>145</th>
      <td>semantic segmentation</td>
      <td>4.090703</td>
    </tr>
    <tr>
      <th>146</th>
      <td>adversarial attacks</td>
      <td>4.088776</td>
    </tr>
    <tr>
      <th>147</th>
      <td>extensive experiments</td>
      <td>4.085855</td>
    </tr>
    <tr>
      <th>148</th>
      <td>recent research</td>
      <td>4.085343</td>
    </tr>
    <tr>
      <th>149</th>
      <td>physical attacks</td>
      <td>4.084913</td>
    </tr>
    <tr>
      <th>150</th>
      <td>easily fool</td>
      <td>4.084821</td>
    </tr>
    <tr>
      <th>151</th>
      <td>natural examples</td>
      <td>4.084158</td>
    </tr>
    <tr>
      <th>152</th>
      <td>gradient masking</td>
      <td>4.083333</td>
    </tr>
    <tr>
      <th>153</th>
      <td>recent works</td>
      <td>4.078159</td>
    </tr>
    <tr>
      <th>154</th>
      <td>networks trained</td>
      <td>4.077771</td>
    </tr>
    <tr>
      <th>155</th>
      <td>distribution set</td>
      <td>4.073289</td>
    </tr>
    <tr>
      <th>156</th>
      <td>adversarial perturbations</td>
      <td>4.067580</td>
    </tr>
    <tr>
      <th>157</th>
      <td>attack algorithms</td>
      <td>4.064940</td>
    </tr>
    <tr>
      <th>158</th>
      <td>point clouds</td>
      <td>4.063492</td>
    </tr>
    <tr>
      <th>159</th>
      <td>threat models</td>
      <td>4.063027</td>
    </tr>
    <tr>
      <th>160</th>
      <td>image space</td>
      <td>4.062949</td>
    </tr>
    <tr>
      <th>161</th>
      <td>target models</td>
      <td>4.062792</td>
    </tr>
    <tr>
      <th>162</th>
      <td>defense techniques</td>
      <td>4.059199</td>
    </tr>
    <tr>
      <th>163</th>
      <td>adversarially trained</td>
      <td>4.056589</td>
    </tr>
    <tr>
      <th>164</th>
      <td>iterative attacks</td>
      <td>4.054633</td>
    </tr>
    <tr>
      <th>165</th>
      <td>adversarial regions</td>
      <td>4.053467</td>
    </tr>
    <tr>
      <th>166</th>
      <td>previous studies</td>
      <td>4.052632</td>
    </tr>
    <tr>
      <th>167</th>
      <td>annotated images</td>
      <td>4.049003</td>
    </tr>
    <tr>
      <th>168</th>
      <td>mutual information</td>
      <td>4.048518</td>
    </tr>
    <tr>
      <th>169</th>
      <td>adversarial settings</td>
      <td>4.046931</td>
    </tr>
    <tr>
      <th>170</th>
      <td>multiple attacks</td>
      <td>4.046647</td>
    </tr>
    <tr>
      <th>171</th>
      <td>art performance</td>
      <td>4.045674</td>
    </tr>
    <tr>
      <th>172</th>
      <td>objective function</td>
      <td>4.045530</td>
    </tr>
    <tr>
      <th>173</th>
      <td>perturbed images</td>
      <td>4.044655</td>
    </tr>
    <tr>
      <th>174</th>
      <td>human eye</td>
      <td>4.042735</td>
    </tr>
    <tr>
      <th>175</th>
      <td>human eyes</td>
      <td>4.042735</td>
    </tr>
    <tr>
      <th>176</th>
      <td>defensive distillation</td>
      <td>4.039855</td>
    </tr>
    <tr>
      <th>177</th>
      <td>activation functions</td>
      <td>4.039702</td>
    </tr>
    <tr>
      <th>178</th>
      <td>universal perturbations</td>
      <td>4.032632</td>
    </tr>
    <tr>
      <th>179</th>
      <td>target image</td>
      <td>4.032613</td>
    </tr>
    <tr>
      <th>180</th>
      <td>defense methods</td>
      <td>4.032352</td>
    </tr>
    <tr>
      <th>181</th>
      <td>object detectors</td>
      <td>4.018018</td>
    </tr>
    <tr>
      <th>182</th>
      <td>real images</td>
      <td>4.015670</td>
    </tr>
    <tr>
      <th>183</th>
      <td>adversarial images</td>
      <td>4.013581</td>
    </tr>
    <tr>
      <th>184</th>
      <td>adversarial perturbation</td>
      <td>4.009172</td>
    </tr>
    <tr>
      <th>185</th>
      <td>defended networks</td>
      <td>4.004516</td>
    </tr>
    <tr>
      <th>186</th>
      <td>random noise</td>
      <td>4.002632</td>
    </tr>
    <tr>
      <th>187</th>
      <td>image classification</td>
      <td>3.998416</td>
    </tr>
    <tr>
      <th>188</th>
      <td>defense strategy</td>
      <td>3.998066</td>
    </tr>
    <tr>
      <th>189</th>
      <td>classification tasks</td>
      <td>3.996337</td>
    </tr>
    <tr>
      <th>190</th>
      <td>critical systems</td>
      <td>3.991866</td>
    </tr>
    <tr>
      <th>191</th>
      <td>input examples</td>
      <td>3.989224</td>
    </tr>
    <tr>
      <th>192</th>
      <td>training samples</td>
      <td>3.985180</td>
    </tr>
    <tr>
      <th>193</th>
      <td>adversarial subspaces</td>
      <td>3.982759</td>
    </tr>
    <tr>
      <th>194</th>
      <td>classification problems</td>
      <td>3.976337</td>
    </tr>
    <tr>
      <th>195</th>
      <td>autonomous vehicles</td>
      <td>3.974662</td>
    </tr>
    <tr>
      <th>196</th>
      <td>multiscale processing</td>
      <td>3.971429</td>
    </tr>
    <tr>
      <th>197</th>
      <td>original images</td>
      <td>3.969882</td>
    </tr>
    <tr>
      <th>198</th>
      <td>video frames</td>
      <td>3.965630</td>
    </tr>
    <tr>
      <th>199</th>
      <td>successfully attack</td>
      <td>3.962578</td>
    </tr>
    <tr>
      <th>200</th>
      <td>based models</td>
      <td>3.958065</td>
    </tr>
    <tr>
      <th>201</th>
      <td>detection method</td>
      <td>3.955988</td>
    </tr>
    <tr>
      <th>202</th>
      <td>random perturbations</td>
      <td>3.955634</td>
    </tr>
    <tr>
      <th>203</th>
      <td>backdoor attacks</td>
      <td>3.955448</td>
    </tr>
    <tr>
      <th>204</th>
      <td>clean examples</td>
      <td>3.953646</td>
    </tr>
    <tr>
      <th>205</th>
      <td>input space</td>
      <td>3.953590</td>
    </tr>
    <tr>
      <th>206</th>
      <td>previous methods</td>
      <td>3.951579</td>
    </tr>
    <tr>
      <th>207</th>
      <td>hidden layers</td>
      <td>3.950549</td>
    </tr>
    <tr>
      <th>208</th>
      <td>visual concepts</td>
      <td>3.950000</td>
    </tr>
    <tr>
      <th>209</th>
      <td>attack methods</td>
      <td>3.949245</td>
    </tr>
    <tr>
      <th>210</th>
      <td>benign examples</td>
      <td>3.946503</td>
    </tr>
    <tr>
      <th>211</th>
      <td>perceptual similarity</td>
      <td>3.937500</td>
    </tr>
    <tr>
      <th>212</th>
      <td>defense mechanisms</td>
      <td>3.934574</td>
    </tr>
    <tr>
      <th>213</th>
      <td>art defenses</td>
      <td>3.930622</td>
    </tr>
    <tr>
      <th>214</th>
      <td>representative natural</td>
      <td>3.925154</td>
    </tr>
    <tr>
      <th>215</th>
      <td>evasion attacks</td>
      <td>3.924198</td>
    </tr>
    <tr>
      <th>216</th>
      <td>learned model</td>
      <td>3.923139</td>
    </tr>
    <tr>
      <th>217</th>
      <td>malware detection</td>
      <td>3.922222</td>
    </tr>
    <tr>
      <th>218</th>
      <td>target label</td>
      <td>3.919423</td>
    </tr>
    <tr>
      <th>219</th>
      <td>clean samples</td>
      <td>3.906526</td>
    </tr>
    <tr>
      <th>220</th>
      <td>boundary attack</td>
      <td>3.905435</td>
    </tr>
    <tr>
      <th>221</th>
      <td>final layer</td>
      <td>3.905376</td>
    </tr>
    <tr>
      <th>222</th>
      <td>results suggest</td>
      <td>3.905000</td>
    </tr>
    <tr>
      <th>223</th>
      <td>input image</td>
      <td>3.894799</td>
    </tr>
    <tr>
      <th>224</th>
      <td>threat model</td>
      <td>3.893908</td>
    </tr>
    <tr>
      <th>225</th>
      <td>target model</td>
      <td>3.893673</td>
    </tr>
    <tr>
      <th>226</th>
      <td>distribution samples</td>
      <td>3.891902</td>
    </tr>
    <tr>
      <th>227</th>
      <td>image regions</td>
      <td>3.890968</td>
    </tr>
    <tr>
      <th>228</th>
      <td>training procedure</td>
      <td>3.890343</td>
    </tr>
    <tr>
      <th>229</th>
      <td>based attack</td>
      <td>3.888384</td>
    </tr>
    <tr>
      <th>230</th>
      <td>training dataset</td>
      <td>3.883166</td>
    </tr>
    <tr>
      <th>231</th>
      <td>image classifiers</td>
      <td>3.881274</td>
    </tr>
    <tr>
      <th>232</th>
      <td>test accuracy</td>
      <td>3.880934</td>
    </tr>
    <tr>
      <th>233</th>
      <td>previous works</td>
      <td>3.879806</td>
    </tr>
    <tr>
      <th>234</th>
      <td>network architectures</td>
      <td>3.867375</td>
    </tr>
    <tr>
      <th>235</th>
      <td>pixel space</td>
      <td>3.864791</td>
    </tr>
    <tr>
      <th>236</th>
      <td>underlying model</td>
      <td>3.863139</td>
    </tr>
    <tr>
      <th>237</th>
      <td>trained models</td>
      <td>3.855514</td>
    </tr>
    <tr>
      <th>238</th>
      <td>models trained</td>
      <td>3.855514</td>
    </tr>
    <tr>
      <th>239</th>
      <td>based attacks</td>
      <td>3.850005</td>
    </tr>
    <tr>
      <th>240</th>
      <td>adversarial inputs</td>
      <td>3.841997</td>
    </tr>
    <tr>
      <th>241</th>
      <td>large margin</td>
      <td>3.841848</td>
    </tr>
    <tr>
      <th>242</th>
      <td>natural images</td>
      <td>3.836657</td>
    </tr>
    <tr>
      <th>243</th>
      <td>social media</td>
      <td>3.833333</td>
    </tr>
    <tr>
      <th>244</th>
      <td>trained network</td>
      <td>3.831256</td>
    </tr>
    <tr>
      <th>245</th>
      <td>recent years</td>
      <td>3.829932</td>
    </tr>
    <tr>
      <th>246</th>
      <td>classified incorrectly</td>
      <td>3.826087</td>
    </tr>
    <tr>
      <th>247</th>
      <td>small perturbations</td>
      <td>3.826079</td>
    </tr>
    <tr>
      <th>248</th>
      <td>adding small</td>
      <td>3.820513</td>
    </tr>
    <tr>
      <th>249</th>
      <td>wide range</td>
      <td>3.802900</td>
    </tr>
    <tr>
      <th>250</th>
      <td>training process</td>
      <td>3.799434</td>
    </tr>
    <tr>
      <th>251</th>
      <td>targeted attacks</td>
      <td>3.799198</td>
    </tr>
    <tr>
      <th>252</th>
      <td>original inputs</td>
      <td>3.798298</td>
    </tr>
    <tr>
      <th>253</th>
      <td>target class</td>
      <td>3.793246</td>
    </tr>
    <tr>
      <th>254</th>
      <td>obfuscated gradients</td>
      <td>3.789474</td>
    </tr>
    <tr>
      <th>255</th>
      <td>art robustness</td>
      <td>3.787081</td>
    </tr>
    <tr>
      <th>256</th>
      <td>input features</td>
      <td>3.785577</td>
    </tr>
    <tr>
      <th>257</th>
      <td>open problem</td>
      <td>3.782609</td>
    </tr>
    <tr>
      <th>258</th>
      <td>training distribution</td>
      <td>3.778317</td>
    </tr>
    <tr>
      <th>259</th>
      <td>classification performance</td>
      <td>3.769284</td>
    </tr>
    <tr>
      <th>260</th>
      <td>critical applications</td>
      <td>3.768182</td>
    </tr>
    <tr>
      <th>261</th>
      <td>small perturbation</td>
      <td>3.767672</td>
    </tr>
    <tr>
      <th>262</th>
      <td>decision boundary</td>
      <td>3.765438</td>
    </tr>
    <tr>
      <th>263</th>
      <td>based system</td>
      <td>3.759140</td>
    </tr>
    <tr>
      <th>264</th>
      <td>decision boundaries</td>
      <td>3.755914</td>
    </tr>
    <tr>
      <th>265</th>
      <td>target person</td>
      <td>3.744820</td>
    </tr>
    <tr>
      <th>266</th>
      <td>input images</td>
      <td>3.741723</td>
    </tr>
    <tr>
      <th>267</th>
      <td>image transformations</td>
      <td>3.711756</td>
    </tr>
    <tr>
      <th>268</th>
      <td>clean images</td>
      <td>3.706146</td>
    </tr>
    <tr>
      <th>269</th>
      <td>model distribution</td>
      <td>3.705658</td>
    </tr>
    <tr>
      <th>270</th>
      <td>large datasets</td>
      <td>3.704348</td>
    </tr>
    <tr>
      <th>271</th>
      <td>large margins</td>
      <td>3.704348</td>
    </tr>
    <tr>
      <th>272</th>
      <td>benchmark datasets</td>
      <td>3.694737</td>
    </tr>
    <tr>
      <th>273</th>
      <td>security concerns</td>
      <td>3.692391</td>
    </tr>
    <tr>
      <th>274</th>
      <td>classification accuracy</td>
      <td>3.690605</td>
    </tr>
    <tr>
      <th>275</th>
      <td>trained model</td>
      <td>3.686395</td>
    </tr>
    <tr>
      <th>276</th>
      <td>art black</td>
      <td>3.684848</td>
    </tr>
    <tr>
      <th>277</th>
      <td>adversarial robustness</td>
      <td>3.678932</td>
    </tr>
    <tr>
      <th>278</th>
      <td>human perception</td>
      <td>3.674314</td>
    </tr>
    <tr>
      <th>279</th>
      <td>differential privacy</td>
      <td>3.669960</td>
    </tr>
    <tr>
      <th>280</th>
      <td>prior knowledge</td>
      <td>3.641446</td>
    </tr>
    <tr>
      <th>281</th>
      <td>facial attributes</td>
      <td>3.625000</td>
    </tr>
    <tr>
      <th>282</th>
      <td>recent advances</td>
      <td>3.617811</td>
    </tr>
    <tr>
      <th>283</th>
      <td>agnostic perturbations</td>
      <td>3.581574</td>
    </tr>
    <tr>
      <th>284</th>
      <td>imperceptible perturbations</td>
      <td>3.578678</td>
    </tr>
    <tr>
      <th>285</th>
      <td>existing black</td>
      <td>3.566760</td>
    </tr>
    <tr>
      <th>286</th>
      <td>ensemble methods</td>
      <td>3.566667</td>
    </tr>
    <tr>
      <th>287</th>
      <td>proposed method</td>
      <td>3.548421</td>
    </tr>
    <tr>
      <th>288</th>
      <td>general framework</td>
      <td>3.548276</td>
    </tr>
    <tr>
      <th>289</th>
      <td>saddle points</td>
      <td>3.545455</td>
    </tr>
    <tr>
      <th>290</th>
      <td>results demonstrate</td>
      <td>3.541782</td>
    </tr>
    <tr>
      <th>291</th>
      <td>robust features</td>
      <td>3.539916</td>
    </tr>
    <tr>
      <th>292</th>
      <td>classifier network</td>
      <td>3.535950</td>
    </tr>
    <tr>
      <th>293</th>
      <td>image classifier</td>
      <td>3.530029</td>
    </tr>
    <tr>
      <th>294</th>
      <td>proposed algorithm</td>
      <td>3.522202</td>
    </tr>
    <tr>
      <th>295</th>
      <td>significantly improve</td>
      <td>3.514310</td>
    </tr>
    <tr>
      <th>296</th>
      <td>mislead dnns</td>
      <td>3.505721</td>
    </tr>
    <tr>
      <th>297</th>
      <td>model architecture</td>
      <td>3.488139</td>
    </tr>
    <tr>
      <th>298</th>
      <td>current state</td>
      <td>3.480563</td>
    </tr>
    <tr>
      <th>299</th>
      <td>highly susceptible</td>
      <td>3.461905</td>
    </tr>
    <tr>
      <th>300</th>
      <td>small subset</td>
      <td>3.452489</td>
    </tr>
    <tr>
      <th>301</th>
      <td>knowledge distillation</td>
      <td>3.424054</td>
    </tr>
    <tr>
      <th>302</th>
      <td>optimization problem</td>
      <td>3.416894</td>
    </tr>
    <tr>
      <th>303</th>
      <td>wide variety</td>
      <td>3.393171</td>
    </tr>
    <tr>
      <th>304</th>
      <td>imagenet datasets</td>
      <td>3.386957</td>
    </tr>
    <tr>
      <th>305</th>
      <td>small number</td>
      <td>3.377622</td>
    </tr>
    <tr>
      <th>306</th>
      <td>model robustness</td>
      <td>3.377493</td>
    </tr>
    <tr>
      <th>307</th>
      <td>proposed approach</td>
      <td>3.361825</td>
    </tr>
    <tr>
      <th>308</th>
      <td>trained classifier</td>
      <td>3.351206</td>
    </tr>
    <tr>
      <th>309</th>
      <td>effective method</td>
      <td>3.350589</td>
    </tr>
    <tr>
      <th>310</th>
      <td>outperforms state</td>
      <td>3.348288</td>
    </tr>
    <tr>
      <th>311</th>
      <td>paper proposes</td>
      <td>3.313860</td>
    </tr>
    <tr>
      <th>312</th>
      <td>safety concerns</td>
      <td>3.291667</td>
    </tr>
    <tr>
      <th>313</th>
      <td>model parameters</td>
      <td>3.263139</td>
    </tr>
    <tr>
      <th>314</th>
      <td>mnist dataset</td>
      <td>3.261418</td>
    </tr>
    <tr>
      <th>315</th>
      <td>variational autoencoder</td>
      <td>3.250000</td>
    </tr>
    <tr>
      <th>316</th>
      <td>easily fooled</td>
      <td>3.232143</td>
    </tr>
    <tr>
      <th>317</th>
      <td>experiments demonstrate</td>
      <td>3.212292</td>
    </tr>
    <tr>
      <th>318</th>
      <td>limited number</td>
      <td>3.204545</td>
    </tr>
    <tr>
      <th>319</th>
      <td>experiments conducted</td>
      <td>3.204082</td>
    </tr>
    <tr>
      <th>320</th>
      <td>cifar10 datasets</td>
      <td>3.192857</td>
    </tr>
    <tr>
      <th>321</th>
      <td>achieved state</td>
      <td>3.187971</td>
    </tr>
    <tr>
      <th>322</th>
      <td>highly vulnerable</td>
      <td>3.187179</td>
    </tr>
    <tr>
      <th>323</th>
      <td>achieving state</td>
      <td>3.151860</td>
    </tr>
    <tr>
      <th>324</th>
      <td>paper presents</td>
      <td>3.140249</td>
    </tr>
    <tr>
      <th>325</th>
      <td>improve robustness</td>
      <td>2.991627</td>
    </tr>
    <tr>
      <th>326</th>
      <td>achieve state</td>
      <td>2.991145</td>
    </tr>
    <tr>
      <th>327</th>
      <td>paper focuses</td>
      <td>2.980527</td>
    </tr>
    <tr>
      <th>328</th>
      <td>widely applied</td>
      <td>2.691860</td>
    </tr>
    <tr>
      <th>329</th>
      <td>10 datasets</td>
      <td>1.800000</td>
    </tr>
  </tbody>
</table>