<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Key Phrase: TF-IDF</th>
      <th>Score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>adversarial example</td>
      <td>0.020695</td>
    </tr>
    <tr>
      <th>1</th>
      <td>neural network</td>
      <td>0.016169</td>
    </tr>
    <tr>
      <th>2</th>
      <td>adversarial attack</td>
      <td>0.011839</td>
    </tr>
    <tr>
      <th>3</th>
      <td>adversarial perturbation</td>
      <td>0.009720</td>
    </tr>
    <tr>
      <th>4</th>
      <td>deep neural</td>
      <td>0.009342</td>
    </tr>
    <tr>
      <th>5</th>
      <td>deep neural network</td>
      <td>0.009234</td>
    </tr>
    <tr>
      <th>6</th>
      <td>state art</td>
      <td>0.009170</td>
    </tr>
    <tr>
      <th>7</th>
      <td>adversarial training</td>
      <td>0.008955</td>
    </tr>
    <tr>
      <th>8</th>
      <td>black box</td>
      <td>0.008096</td>
    </tr>
    <tr>
      <th>9</th>
      <td>deep learning</td>
      <td>0.007000</td>
    </tr>
    <tr>
      <th>10</th>
      <td>vulnerable adversarial</td>
      <td>0.005684</td>
    </tr>
    <tr>
      <th>11</th>
      <td>machine learn</td>
      <td>0.005511</td>
    </tr>
    <tr>
      <th>12</th>
      <td>machine learning</td>
      <td>0.005492</td>
    </tr>
    <tr>
      <th>13</th>
      <td>adversarial image</td>
      <td>0.005255</td>
    </tr>
    <tr>
      <th>14</th>
      <td>learning model</td>
      <td>0.005109</td>
    </tr>
    <tr>
      <th>15</th>
      <td>box attack</td>
      <td>0.005061</td>
    </tr>
    <tr>
      <th>16</th>
      <td>adversarial sample</td>
      <td>0.004963</td>
    </tr>
    <tr>
      <th>17</th>
      <td>generate adversarial</td>
      <td>0.004626</td>
    </tr>
    <tr>
      <th>18</th>
      <td>image classification</td>
      <td>0.004563</td>
    </tr>
    <tr>
      <th>19</th>
      <td>network dnn</td>
      <td>0.004469</td>
    </tr>
    <tr>
      <th>20</th>
      <td>neural network dnn</td>
      <td>0.004469</td>
    </tr>
    <tr>
      <th>21</th>
      <td>convolutional neural network</td>
      <td>0.004086</td>
    </tr>
    <tr>
      <th>22</th>
      <td>convolutional neural</td>
      <td>0.004086</td>
    </tr>
    <tr>
      <th>23</th>
      <td>real world</td>
      <td>0.004011</td>
    </tr>
    <tr>
      <th>24</th>
      <td>propose method</td>
      <td>0.003995</td>
    </tr>
    <tr>
      <th>25</th>
      <td>black box attack</td>
      <td>0.003932</td>
    </tr>
    <tr>
      <th>26</th>
      <td>paper propose</td>
      <td>0.003890</td>
    </tr>
    <tr>
      <th>27</th>
      <td>training datum</td>
      <td>0.003829</td>
    </tr>
    <tr>
      <th>28</th>
      <td>white box</td>
      <td>0.003692</td>
    </tr>
    <tr>
      <th>29</th>
      <td>vulnerable adversarial example</td>
      <td>0.003510</td>
    </tr>
    <tr>
      <th>30</th>
      <td>improve robustness</td>
      <td>0.003433</td>
    </tr>
    <tr>
      <th>31</th>
      <td>success rate</td>
      <td>0.003363</td>
    </tr>
    <tr>
      <th>32</th>
      <td>attack method</td>
      <td>0.003356</td>
    </tr>
    <tr>
      <th>33</th>
      <td>machine learning model</td>
      <td>0.003342</td>
    </tr>
    <tr>
      <th>34</th>
      <td>mnist cifar</td>
      <td>0.003321</td>
    </tr>
    <tr>
      <th>35</th>
      <td>deep network</td>
      <td>0.003238</td>
    </tr>
    <tr>
      <th>36</th>
      <td>training set</td>
      <td>0.003179</td>
    </tr>
    <tr>
      <th>37</th>
      <td>generate adversarial example</td>
      <td>0.003171</td>
    </tr>
    <tr>
      <th>38</th>
      <td>computer vision</td>
      <td>0.003110</td>
    </tr>
    <tr>
      <th>39</th>
      <td>detect adversarial</td>
      <td>0.003050</td>
    </tr>
    <tr>
      <th>40</th>
      <td>train model</td>
      <td>0.003021</td>
    </tr>
    <tr>
      <th>41</th>
      <td>perturbation input</td>
      <td>0.002916</td>
    </tr>
    <tr>
      <th>42</th>
      <td>experimental result</td>
      <td>0.002916</td>
    </tr>
    <tr>
      <th>43</th>
      <td>adversarial network</td>
      <td>0.002817</td>
    </tr>
    <tr>
      <th>44</th>
      <td>base attack</td>
      <td>0.002781</td>
    </tr>
    <tr>
      <th>45</th>
      <td>result show</td>
      <td>0.002771</td>
    </tr>
    <tr>
      <th>46</th>
      <td>input image</td>
      <td>0.002769</td>
    </tr>
    <tr>
      <th>47</th>
      <td>adversarial robustness</td>
      <td>0.002742</td>
    </tr>
    <tr>
      <th>48</th>
      <td>learn algorithm</td>
      <td>0.002715</td>
    </tr>
    <tr>
      <th>49</th>
      <td>generative adversarial</td>
      <td>0.002665</td>
    </tr>
    <tr>
      <th>50</th>
      <td>deep learn</td>
      <td>0.002639</td>
    </tr>
    <tr>
      <th>51</th>
      <td>generative model</td>
      <td>0.002596</td>
    </tr>
    <tr>
      <th>52</th>
      <td>small perturbation</td>
      <td>0.002586</td>
    </tr>
    <tr>
      <th>53</th>
      <td>target model</td>
      <td>0.002576</td>
    </tr>
    <tr>
      <th>54</th>
      <td>robustness adversarial</td>
      <td>0.002563</td>
    </tr>
    <tr>
      <th>55</th>
      <td>recent work</td>
      <td>0.002538</td>
    </tr>
    <tr>
      <th>56</th>
      <td>deep learning model</td>
      <td>0.002503</td>
    </tr>
    <tr>
      <th>57</th>
      <td>network adversarial</td>
      <td>0.002500</td>
    </tr>
    <tr>
      <th>58</th>
      <td>classification task</td>
      <td>0.002486</td>
    </tr>
    <tr>
      <th>59</th>
      <td>natural image</td>
      <td>0.002480</td>
    </tr>
    <tr>
      <th>60</th>
      <td>experiment show</td>
      <td>0.002460</td>
    </tr>
    <tr>
      <th>61</th>
      <td>decision boundary</td>
      <td>0.002439</td>
    </tr>
    <tr>
      <th>62</th>
      <td>generative adversarial network</td>
      <td>0.002437</td>
    </tr>
    <tr>
      <th>63</th>
      <td>threat model</td>
      <td>0.002423</td>
    </tr>
    <tr>
      <th>64</th>
      <td>network train</td>
      <td>0.002390</td>
    </tr>
    <tr>
      <th>65</th>
      <td>defense method</td>
      <td>0.002361</td>
    </tr>
    <tr>
      <th>66</th>
      <td>face recognition</td>
      <td>0.002329</td>
    </tr>
    <tr>
      <th>67</th>
      <td>robust adversarial</td>
      <td>0.002326</td>
    </tr>
    <tr>
      <th>68</th>
      <td>object detection</td>
      <td>0.002320</td>
    </tr>
    <tr>
      <th>69</th>
      <td>extensive experiment</td>
      <td>0.002208</td>
    </tr>
    <tr>
      <th>70</th>
      <td>universal perturbation</td>
      <td>0.002161</td>
    </tr>
    <tr>
      <th>71</th>
      <td>object detector</td>
      <td>0.002147</td>
    </tr>
    <tr>
      <th>72</th>
      <td>imperceptible perturbation</td>
      <td>0.002131</td>
    </tr>
    <tr>
      <th>73</th>
      <td>example generate</td>
      <td>0.002126</td>
    </tr>
    <tr>
      <th>74</th>
      <td>image classifier</td>
      <td>0.002119</td>
    </tr>
    <tr>
      <th>75</th>
      <td>vulnerable adversarial attack</td>
      <td>0.002111</td>
    </tr>
    <tr>
      <th>76</th>
      <td>network architecture</td>
      <td>0.002090</td>
    </tr>
    <tr>
      <th>77</th>
      <td>learning system</td>
      <td>0.002083</td>
    </tr>
    <tr>
      <th>78</th>
      <td>adversarial example generate</td>
      <td>0.002075</td>
    </tr>
    <tr>
      <th>79</th>
      <td>network vulnerable</td>
      <td>0.002071</td>
    </tr>
    <tr>
      <th>80</th>
      <td>adversarial input</td>
      <td>0.002070</td>
    </tr>
    <tr>
      <th>81</th>
      <td>detect adversarial example</td>
      <td>0.002055</td>
    </tr>
    <tr>
      <th>82</th>
      <td>work show</td>
      <td>0.002038</td>
    </tr>
    <tr>
      <th>83</th>
      <td>show vulnerable</td>
      <td>0.002022</td>
    </tr>
    <tr>
      <th>84</th>
      <td>method generate</td>
      <td>0.002016</td>
    </tr>
    <tr>
      <th>85</th>
      <td>state art performance</td>
      <td>0.002002</td>
    </tr>
    <tr>
      <th>86</th>
      <td>art performance</td>
      <td>0.002002</td>
    </tr>
    <tr>
      <th>87</th>
      <td>recent study</td>
      <td>0.001992</td>
    </tr>
    <tr>
      <th>88</th>
      <td>loss function</td>
      <td>0.001958</td>
    </tr>
    <tr>
      <th>89</th>
      <td>propose defense</td>
      <td>0.001942</td>
    </tr>
    <tr>
      <th>90</th>
      <td>bad case</td>
      <td>0.001934</td>
    </tr>
    <tr>
      <th>91</th>
      <td>high dimensional</td>
      <td>0.001926</td>
    </tr>
    <tr>
      <th>92</th>
      <td>neural network vulnerable</td>
      <td>0.001906</td>
    </tr>
    <tr>
      <th>93</th>
      <td>achieve state art</td>
      <td>0.001900</td>
    </tr>
    <tr>
      <th>94</th>
      <td>achieve state</td>
      <td>0.001900</td>
    </tr>
    <tr>
      <th>95</th>
      <td>network vulnerable adversarial</td>
      <td>0.001870</td>
    </tr>
    <tr>
      <th>96</th>
      <td>adversarial defense</td>
      <td>0.001842</td>
    </tr>
    <tr>
      <th>97</th>
      <td>safety critical</td>
      <td>0.001832</td>
    </tr>
    <tr>
      <th>98</th>
      <td>art attack</td>
      <td>0.001829</td>
    </tr>
    <tr>
      <th>99</th>
      <td>learn model</td>
      <td>0.001824</td>
    </tr>
    <tr>
      <th>100</th>
      <td>defense mechanism</td>
      <td>0.001822</td>
    </tr>
    <tr>
      <th>101</th>
      <td>imperceptible human</td>
      <td>0.001800</td>
    </tr>
    <tr>
      <th>102</th>
      <td>wide range</td>
      <td>0.001795</td>
    </tr>
    <tr>
      <th>103</th>
      <td>recognition system</td>
      <td>0.001795</td>
    </tr>
    <tr>
      <th>104</th>
      <td>attack algorithm</td>
      <td>0.001793</td>
    </tr>
    <tr>
      <th>105</th>
      <td>network cnn</td>
      <td>0.001791</td>
    </tr>
    <tr>
      <th>106</th>
      <td>neural network adversarial</td>
      <td>0.001781</td>
    </tr>
    <tr>
      <th>107</th>
      <td>state art attack</td>
      <td>0.001779</td>
    </tr>
    <tr>
      <th>108</th>
      <td>attack adversarial</td>
      <td>0.001771</td>
    </tr>
    <tr>
      <th>109</th>
      <td>craft adversarial</td>
      <td>0.001770</td>
    </tr>
    <tr>
      <th>110</th>
      <td>model train</td>
      <td>0.001751</td>
    </tr>
    <tr>
      <th>111</th>
      <td>show adversarial</td>
      <td>0.001745</td>
    </tr>
    <tr>
      <th>112</th>
      <td>point cloud</td>
      <td>0.001745</td>
    </tr>
    <tr>
      <th>113</th>
      <td>adversarial noise</td>
      <td>0.001738</td>
    </tr>
    <tr>
      <th>114</th>
      <td>defense adversarial</td>
      <td>0.001737</td>
    </tr>
    <tr>
      <th>115</th>
      <td>neural network cnn</td>
      <td>0.001735</td>
    </tr>
    <tr>
      <th>116</th>
      <td>propose algorithm</td>
      <td>0.001728</td>
    </tr>
    <tr>
      <th>117</th>
      <td>train deep</td>
      <td>0.001713</td>
    </tr>
    <tr>
      <th>118</th>
      <td>test time</td>
      <td>0.001711</td>
    </tr>
    <tr>
      <th>119</th>
      <td>image space</td>
      <td>0.001709</td>
    </tr>
    <tr>
      <th>120</th>
      <td>work propose</td>
      <td>0.001707</td>
    </tr>
    <tr>
      <th>121</th>
      <td>carefully craft</td>
      <td>0.001684</td>
    </tr>
    <tr>
      <th>122</th>
      <td>deep convolutional</td>
      <td>0.001683</td>
    </tr>
    <tr>
      <th>123</th>
      <td>white box attack</td>
      <td>0.001673</td>
    </tr>
    <tr>
      <th>124</th>
      <td>vulnerable adversarial perturbation</td>
      <td>0.001641</td>
    </tr>
    <tr>
      <th>125</th>
      <td>pre train</td>
      <td>0.001631</td>
    </tr>
    <tr>
      <th>126</th>
      <td>robustness deep</td>
      <td>0.001624</td>
    </tr>
    <tr>
      <th>127</th>
      <td>network show</td>
      <td>0.001615</td>
    </tr>
    <tr>
      <th>128</th>
      <td>model adversarial</td>
      <td>0.001594</td>
    </tr>
    <tr>
      <th>129</th>
      <td>study show</td>
      <td>0.001594</td>
    </tr>
    <tr>
      <th>130</th>
      <td>cifar imagenet</td>
      <td>0.001593</td>
    </tr>
    <tr>
      <th>131</th>
      <td>box adversarial</td>
      <td>0.001590</td>
    </tr>
    <tr>
      <th>132</th>
      <td>defensive distillation</td>
      <td>0.001588</td>
    </tr>
    <tr>
      <th>133</th>
      <td>machine learn algorithm</td>
      <td>0.001585</td>
    </tr>
    <tr>
      <th>134</th>
      <td>original image</td>
      <td>0.001584</td>
    </tr>
    <tr>
      <th>135</th>
      <td>show propose</td>
      <td>0.001583</td>
    </tr>
    <tr>
      <th>136</th>
      <td>large scale</td>
      <td>0.001581</td>
    </tr>
    <tr>
      <th>137</th>
      <td>universal adversarial</td>
      <td>0.001572</td>
    </tr>
    <tr>
      <th>138</th>
      <td>poisoning attack</td>
      <td>0.001571</td>
    </tr>
    <tr>
      <th>139</th>
      <td>increase robustness</td>
      <td>0.001558</td>
    </tr>
    <tr>
      <th>140</th>
      <td>input datum</td>
      <td>0.001545</td>
    </tr>
    <tr>
      <th>141</th>
      <td>find adversarial</td>
      <td>0.001541</td>
    </tr>
    <tr>
      <th>142</th>
      <td>recent year</td>
      <td>0.001533</td>
    </tr>
    <tr>
      <th>143</th>
      <td>network model</td>
      <td>0.001533</td>
    </tr>
    <tr>
      <th>144</th>
      <td>defend adversarial</td>
      <td>0.001516</td>
    </tr>
    <tr>
      <th>145</th>
      <td>defense strategy</td>
      <td>0.001515</td>
    </tr>
    <tr>
      <th>146</th>
      <td>previous work</td>
      <td>0.001509</td>
    </tr>
    <tr>
      <th>147</th>
      <td>semantic segmentation</td>
      <td>0.001498</td>
    </tr>
    <tr>
      <th>148</th>
      <td>dataset show</td>
      <td>0.001494</td>
    </tr>
    <tr>
      <th>149</th>
      <td>base adversarial</td>
      <td>0.001492</td>
    </tr>
  </tbody>
</table>